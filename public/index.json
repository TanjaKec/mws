[{"authors":null,"categories":null,"content":"I am a long-time R user with a doctorate in Statistics from the University of Manchester. I spent many years working in the U.K. university sector as a senior lecturer and have published an extensive number of articles and papers in the field of quantile regression. I love sharing knowledge and I use R to create various platforms with education materials that can help people learn to extract insights from data. Unsurprisingly, I am an enthusiastic R user and in addition to my involvement supporting women in STEM related activities, I am dedicated to creating an inclusive culture by developing initiatives supporting all underrepresented groups within the DS community.\n  Download my resum√©.\n","date":1404777600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1404777600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/tatjana-kecojevic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tatjana-kecojevic/","section":"authors","summary":"I am a long-time R user with a doctorate in Statistics from the University of Manchester. I spent many years working in the U.K. university sector as a senior lecturer and have published an extensive number of articles and papers in the field of quantile regression.","tags":null,"title":"Tatjana Kecojevic","type":"authors"},{"authors":["Âê≥ÊÅ©ÈÅî"],"categories":null,"content":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"My recent courses Here you will find some of the courses which I have recently delivered. They serve as individual units and you can access them by clicking on their titles on the left hand side. I hope you will enjoy them.\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"ea3d8a60b91bf3250c437528b104e234","permalink":"/training/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/training/example/","section":"training","summary":"During my lecturing career I was incredibly fortunate to work with some truly amazing colleagues who helped me explore and develop my own teaching philosophy and practice. I gained valuable experience in developing, designing and teaching data analysis modules at varying levels of undergraduate and graduate courses. In particular I mastered my teaching skills by lecturing with George Rawlings and Ian McGowan on decision modelling modules. They taught me how to teach basic statistical concepts, which theoretically may be perceived as complex, in an effective way by emphasising concepts over formulae, engaging students to reason rather than to memorise.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":" The ever emerging Internet of Things (IoT) produces vast amounts of data that can be analysed to gain useful insights into trends. The R language is widely used by statisticians for data analysis, and the popularity of R programming has increased greatly in the recent years.\nIn this workshop we teach you to ‚Äòspeak data using R‚Äô by taking a step by step approach, starting by explaining core programming principles of the R programming language, to importing data and employing basic wrangling techniques and the grammar of graphics‚Äô philosophy. This will enable you to produce compelling visualisations that can ultimately illustrate useful insights from your data.\nThrough a series of demonstrations and hands on exercises you will learn some of the fundamental concepts of R and you will get to know how to use its tools in a typical data science project. We will introduce you to graphical and numerical techniques for exploring the information concealed within a dataset. After we develop an understanding of our data we will use R‚Äôs reproducible approach in telling our data story by creating R-Markdown documents.\nAt the end of the workshop, participants will be able to:\n Import data from different sources into the R environment Carry out basic data pre-processing \u0026amp; wrangling Learn to distinguish the most appropriate visualisations to be used for any given data challenge Build advanced visualisations: graphs and maps Gain proficiency in data pre-processing, data wrangling and visualisation in R by putting acquired knowledge into application, adopting a reproducible approach through the creation of RMarkdown documents   This course is available at üëâ https://introtor.netlify.app/   üëâ Go to the following GitHub repo to download the material: https://github.com/TanjaKec/ASDA\nThis workshop has been delivered for ASDA data development training.\nThe workshop has been delivered in partnership with GEOLYTIX.\n","date":1605826800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605826800,"objectID":"377da8a6067a76f6104b36dd6a5ad203","permalink":"/training/example/example4/","publishdate":"2020-11-20T00:00:00+01:00","relpermalink":"/training/example/example4/","section":"training","summary":"The ever emerging Internet of Things (IoT) produces vast amounts of data that can be analysed to gain useful insights into trends. The R language is widely used by statisticians for data analysis, and the popularity of R programming has increased greatly in the recent years.","tags":null,"title":"Learn to access, organise, analyse and argue with data using R","type":"docs"},{"authors":null,"categories":null,"content":" The workshop provides a practical guide for crateing websites using the blogdown package in R that allows you to create websites from R Markdown files using Hugo, an open-source static site generator written in Go. In this workshop you learn how to create dynamic R Markdown documents to build static websites allowing you to use R code to render the results of your analysis. The blogdown through the use of R Markdown allows technical writing allowing you to add graphs, tables, LaTeX equations, theorems, citations, and references. This makes blogdown an perfect tool for designing websites to communicate your R data story telling or just awesome general-purpose websites. After you create your awesome website using the blogdown and Hugo template you can push it onto your GitHub and deploy on Netlify all free of charge.\nObjectives:\n Apply HUGO theme to create a website using the blogdown Personalise the website Deploy site from your computer to the Internet Use GitHub for version control Use Netlify for continuous deployment Updating your website: serving site, push to GitHub, deploy   This course is available at üëâ https://websiteinr.netlify.app/   üëâ Go to the following GitHub repo to download the material: https://github.com/TanjaKec/eRum2020 and follow the steps given in the Xaringan presentation available from üëâ here\n  Figure 1: Xaringan presentation  The workshop has been delivered at eRum!2020 - European R Users Meeting\n","date":1593903600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593903600,"objectID":"b257820fa8e0a559fed54964fc82d724","permalink":"/training/example/example2/","publishdate":"2020-07-05T00:00:00+01:00","relpermalink":"/training/example/example2/","section":"training","summary":"The workshop provides a practical guide for crateing websites using the blogdown package in R that allows you to create websites from R Markdown files using Hugo, an open-source static site generator written in Go.","tags":null,"title":"Build a website with blogdown in R","type":"docs"},{"authors":null,"categories":null,"content":" This course is designed to give you an appreciation of R programming as a tool for reproducible research. It focuses on packages that will help you access your data, do necessary visualisation and communication in a dynamic and reproducible manner.\nIf you would like to learn to:  Store in one place your research methods, results and interpretation Update your research methodology and automate the update of the results Write your research text and code in R Markdown Generate reproducible reports that display your code and results Assemble your research reporting as either HTML, a PDF or a Word document using the package rmarkdown   then this course is for you!  This course is available at üëâ https://reproducibleresearchinr.rbind.io   The course has been delivered at Belgrade Open School (BOS) and the Institute of Philosophy and Social Theory (IFDT) at the University of Belograde.\n ","date":1581721200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581721200,"objectID":"c7bf03d2a83056a9e286b165163e9d60","permalink":"/training/example/example1/","publishdate":"2020-02-15T00:00:00+01:00","relpermalink":"/training/example/example1/","section":"training","summary":"This course is designed to give you an appreciation of R programming as a tool for reproducible research. It focuses on packages that will help you access your data, do necessary visualisation and communication in a dynamic and reproducible manner.","tags":null,"title":"Reproducible Research","type":"docs"},{"authors":null,"categories":null,"content":" This course is designed to give you an appreciation of R programming as a tool for data exploration. It focuses on packages that will help you do exploratory data analysis, visualisation and communication in a dynamic and reproducible manner.\nIf you would like to:  Discover how to find and access data and prepare it for exploration and visualistion Learn to explore, visualize, and analyse data in a dynamic and reproducible manner Gain experience in data wrangling, exploratory data analysis and data visualisation, and effective communication of results Work on case studies inspired by real problems and based on open data   then this course is for you! üòÄ  This course is available at üëâ https://datachallengewithr.rbind.io/   This workshop is a part of The Autumn Data School program organised as a part of the Open Data - Open Opportunities project.\nYou can download the Autumn Data School program from here üëá\nThe workshop has been delivered in partnership with UNDP Serbia\n ","date":1572735600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572735600,"objectID":"9c89db77dff1f0c94bf1305194fe63dc","permalink":"/training/example/example3/","publishdate":"2019-11-03T00:00:00+01:00","relpermalink":"/training/example/example3/","section":"training","summary":"This course is designed to give you an appreciation of R programming as a tool for data exploration. It focuses on packages that will help you do exploratory data analysis, visualisation and communication in a dynamic and reproducible manner.","tags":null,"title":"Data challenge with R","type":"docs"},{"authors":null,"categories":null,"content":"         Open data belongs to everyone; it empowers people to make informed decisions that are not clouded by misinformation, rumour and gossip. To be able to identify the underlying facts within data sets, it is crucial that individuals and communities possess the necessary skills. Open data is often inconsistent and limited and requires a significant amount of time to organise and structure for presentation purposes.\nThis is a data analysis report concerning the visualisation of the COVID-19 virus within the United Kingdom and Europe. All of the report is created with R. It represents a case study as an illustration of the concepts presented at the workshop on basic R for data analysts. To learn how to use R and develop a report like this visit the Introduction To R website.\nCovid-19: Open Data The novel coronavirus disease 2019 (COVID-19) was first reported in Wuhan, China, where the initial wave of intense community transmissions was cut short by interventions.\n\u0026gt; # If you don\u0026#39;t have the \u0026quot;leaflet\u0026quot; package installed yet, uncomment and run the line below \u0026gt; #install.packages(\u0026quot;leaflet\u0026quot;) \u0026gt; library(leaflet) \u0026gt; # Initialize and assign as the leaflet object \u0026gt; leaflet() %\u0026gt;% + # add tiles to the leaflet object + addTiles() %\u0026gt;% + # setting the centre of the map and the zoom level + setView(lng = 114.3055, lat = 30.5928 , zoom = 10) %\u0026gt;% + # add a popup marker + addMarkers(lng = 114.3055, lat = 30.5928, popup = \u0026quot;\u0026lt;b\u0026gt;Wuhan, capital of Central China‚Äôs Hubei province\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;a href=\u0026#39;https://www.ft.com/content/82574e3d-1633-48ad-8afb-71ebb3fe3dee\u0026#39;\u0026gt;China and Covid-19: what went wrong in Wuhan?\u0026lt;/a\u0026gt;\u0026quot;)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addMarkers\",\"args\":[30.5928,114.3055,null,null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},\"Wuhan, capital of Central China‚Äôs Hubei province\nChina and Covid-19: what went wrong in Wuhan?\",null,null,null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"setView\":[[30.5928,114.3055],10,[]],\"limits\":{\"lat\":[30.5928,30.5928],\"lng\":[114.3055,114.3055]}},\"evals\":[],\"jsHooks\":[]} Experience has shown that for public health intervention to be successful governmental authorities need to:\n identify the infected and provide treatment locate and quarantine all those who had contact with the infected sterilise environmental pathogens promote the use of masks and social distancing release to the public the number of new infections and deaths on a daily basis through open data  The importance of hand washing, wearing a mask and social distancing as a tool to limit disease transmission is well recognised, but nonetheless ensuring social distancing especially in densely populated urban areas is still challenging. Well-educated communities are critical for an effective response and for the prevention of local outbreaks. The sharing of factual information that can be understood and trusted by the communities in bringing about a change in their behaviour to implement efficiently desired public health actions is a must. Trust and transparency are fundamental in obtaining absolute public engagement. The publishing of daily figures that can be freely analysed and scrutinised can help in engaging communities and obtaining its willing and continued support in controlling the spread of infection.\nWorking with a DB in R In big organisations data is often kept in a database and data you wish to access from it might be too large to fit into the memory of your computer. Connecting from R to a database to access the necessary data for an analysis can be very useful, as it allows you to fetch only the chunks needed for the current study. R enables you to access and query a database without having to download the data contained in it. The two most common methods of connection are:\n Option 1)  the RODBC package: uses slightly older code; it can be used to connect to anything that uses ODBC.   \u0026gt; library(\u0026quot;RODBC\u0026quot;) \u0026gt; # Connection with a server called \u0026quot;Walmart\u0026quot; and a database called \u0026quot;Asda\u0026quot;: \u0026gt; RODBC_connection \u0026lt;- odbcDriverConnect(\u0026#39;driver = {SQL Server}; + server = Walmart; + database = Asda; + trusted_connection = true\u0026#39;) #passes your windows credentials to the server; can also specify a username `uid` and a password `pwd` \u0026gt; dt1 \u0026lt;- sqlFetch(channel = RODBC_connection, sqtable = \u0026quot;MyTable\u0026quot;) Using RODBC you can write back to database tables, choosing to append or not:\n\u0026gt; sqlSave(channel = RODBC_connection, + dat = dt2, + tablename = \u0026quot;MyTable_R_version\u0026quot;, + append = FALSE, + safer = FALSE) When you finish working using the database you should disconnect from the server.\n\u0026gt; odbcClose(RODBC_connection) One of the authors of this package is the famous statistician Brian Ripley, and you can find more about the possibilities it offers by playing around with it using the guidance from RDocumentation on RODBC v1.3-17.\n Option 2)  the DBI package: a common database interface in R; can be used with different ‚Äòback-end‚Äô drivers such as MySQL, SQL Server, SQLite, Oracle etc; to write SQL it can be used on its own:   \u0026gt; # Can write an SQL query directly using the `dbSendQuery` function \u0026gt; # Executes the query on the server-side only, but if you want the results back in R, you need to use `dbFetch` \u0026gt; SomeRecords \u0026lt;- dbFetch(dbSendQuery(DBI_Connection, + \u0026quot;SELECT CustomerName_column, City_column FROM Customers_Table\u0026quot;))  You can also write back to a database using the dbWriteTable function.\n\u0026gt; #Writing a new table called \u0026#39;Table_created_in_R\u0026#39; using the R data.frame called \u0026quot;my_df\u0026quot;, with `append` and `overwrite` options \u0026gt; dbWriteTable(DBI_Connection,\u0026quot;Table_created_in_R\u0026quot;, my_df, overwrite = TRUE) We use tbl() to define a table as if it were part of the R work-space, and to specify as the function‚Äôs arguments the connection object and the name of the table in the database.\n\u0026gt; MyTable_Rws \u0026lt;- tbl(DBI_Connection, \u0026quot;MyTable_DB\u0026quot;) If we need to pull the data from the server into R‚Äôs memory we can use the collect() function.\nThe DBI package can be combined with:\n the dplyr package: to make the tbls and to work on them using the dplyr syntax the dbplyr package: allows translation of SQL to dplyr the odbcpackage: provides the odbc drivers, but you could use the functions below with other drivers instead  \u0026gt; DBI_Connection \u0026lt;- dbConnect(odbc(), + driver = \u0026quot;SQL Server\u0026quot;, + server = Sys.getenv(\u0026quot;SERVER\u0026quot;), + database = Sys.getenv(\u0026quot;DATABASE\u0026quot;) + ) With the wave of tidy verse evangelists the second option has become more popular as it allows us to convert SQL into R using the dplyr commands chained with the pipe (%\u0026gt;%) operator. dplyr can translate many different query types into SQL. We can use it to do fairly complex queries without translation in just a few lines and obtain the results even though the data is still in the database.\nUseful DBI commands\n  Command Summary    dbConnect() Create a DBI connection object  dbListTables() List the tables on the connection  dbListFields() List the fields for a given table on a given connection  dbSendQuery() Send a query to execute on the server/connection  dbFetch() Fetch the results from the server/connection  dbWriteTable() Write a table to the connection  tbl() Set a table on the connection as a tibble for dplyr  glimpse() See a summary of the rows, data types and top rows     Reading Data European Centre for Disease Prevention and Control provides daily updates of newly reported cases of COVID-19 by country worldwide. The downloadable data file is updated daily and contains the latest available public data on COVID-19. Each row/entry contains the number of new cases reported per country and per day (with a lag of a day).\nhttps://www.ecdc.europa.eu/en/publications-data/download-data-response-measures-covid-19\nhttps://www.ecdc.europa.eu/en/cases-2019-ncov-eueea\nWe will start the analysis by uploading the necessary packages and data into R. If you have not got the packages used in the following code, you will need to uncomment the first line (delete the # symbol) in the code below.\n\u0026gt; #install.packages(c(\u0026quot;dplyr\u0026quot;, \u0026quot;stringr\u0026quot;)) # install multiple packages by passing a vector of package names to the function; this function will install the requested packages, along with any of their non-optional dependencies \u0026gt; suppressPackageStartupMessages(library(readxl)) \u0026gt; suppressPackageStartupMessages(library(tidyverse)) \u0026gt; suppressPackageStartupMessages(library(httr)) \u0026gt; suppressPackageStartupMessages(library(lubridate)) \u0026gt; suppressPackageStartupMessages(library(dplyr)) \u0026gt; suppressPackageStartupMessages(library(plotly)) \u0026gt; suppressPackageStartupMessages(library(ggplot2)) \u0026gt; suppressPackageStartupMessages(library(cowplot)) \u0026gt; suppressPackageStartupMessages(library(scales)) \u0026gt; suppressPackageStartupMessages(library(sf)) \u0026gt; suppressPackageStartupMessages(library(DBI)) \u0026gt; suppressPackageStartupMessages(library(dbplyr)) \u0026gt; suppressPackageStartupMessages(library(tmap)) \u0026gt; suppressPackageStartupMessages(library(tmaptools)) \u0026gt; \u0026gt; \u0026gt; url2ecdc \u0026lt;- \u0026quot;https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-2020-11-30.xlsx\u0026quot; \u0026gt; \u0026gt; suppressMessages(GET(url2ecdc, write_disk(tf \u0026lt;- tempfile(fileext = \u0026quot;.xlsx\u0026quot;)))) ## Response [https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-2020-11-30.xlsx] ## Date: 2020-12-08 16:35 ## Status: 200 ## Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet ## Size: 3.41 MB ## \u0026lt;ON DISK\u0026gt; /var/folders/71/96w85flx3yl928r2hzpfwvd00000gp/T//RtmpR1zsgo/file14cad6033add9.xlsx \u0026gt; covid_world \u0026lt;- read_excel(tf) We will set up the database connection to work on covid_world data.\n\u0026gt; SQLcon \u0026lt;- dbConnect(RSQLite::SQLite(), \u0026quot;:memory:\u0026quot;) \u0026gt; dbWriteTable(SQLcon, \u0026quot;covid\u0026quot;, covid_world, overwrite=TRUE) Let‚Äôs see what tables we have in our database.\n\u0026gt; dbListTables(SQLcon) ## [1] \u0026quot;covid\u0026quot; We can list the fields in a table:\n\u0026gt; dbListFields(SQLcon, name = \u0026quot;covid\u0026quot;) ## [1] \u0026quot;dateRep\u0026quot; ## [2] \u0026quot;day\u0026quot; ## [3] \u0026quot;month\u0026quot; ## [4] \u0026quot;year\u0026quot; ## [5] \u0026quot;cases\u0026quot; ## [6] \u0026quot;deaths\u0026quot; ## [7] \u0026quot;countriesAndTerritories\u0026quot; ## [8] \u0026quot;geoId\u0026quot; ## [9] \u0026quot;countryterritoryCode\u0026quot; ## [10] \u0026quot;popData2019\u0026quot; ## [11] \u0026quot;continentExp\u0026quot; ## [12] \u0026quot;Cumulative_number_for_14_days_of_COVID-19_cases_per_100000\u0026quot; We can run an SQL query directly from R. To illustrate it we will run a query to obtain distinct values for the field ‚ÄúcontinentExp‚Äù.\n\u0026gt; dbFetch(dbSendQuery(SQLcon, \u0026quot;Select distinct continentExp from covid\u0026quot;)) ## continentExp ## 1 Asia ## 2 Europe ## 3 Africa ## 4 America ## 5 Oceania ## 6 Other Next, we will run a query to count how many entries we have for each continent\n\u0026gt; dbFetch( + dbSendQuery(SQLcon, + \u0026quot;Select continentExp, count(*) as Count + from covid + group by continentExp\u0026quot;)) ## continentExp Count ## 1 Africa 14196 ## 2 America 13056 ## 3 Asia 12653 ## 4 Europe 16601 ## 5 Oceania 2332 ## 6 Other 64 and see how many entries there are for the UK, using a where clause.\n\u0026gt; dbFetch( + dbSendQuery(SQLcon, + \u0026quot;Select continentExp, count(*) as Count + from covid + Where countriesAndTerritories = \u0026#39;United_Kingdom\u0026#39; + group by continentExp\u0026quot;)) ## continentExp Count ## 1 Europe 336 Fortunately for people who are rusty with SQL, and who don‚Äôt feel like learning both SQL and R, we can do all of this using the diplyr package in R.\nFirst we need to declare covid as a tbl for use with dplyr. We‚Äôll call it covid_ecdc to avoid any confusion.\n\u0026gt; covid_ecdc \u0026lt;- tbl(SQLcon, \u0026quot;covid\u0026quot;) This will now be treated as an R tibble, but it is still in the database!!!\nIt is always useful to have a quick glance at the data set structure to find out how the information it contains is structured. Knowledge of the structure is important, because it allows us later to filter out the desired information very precisely based on criteria to limit specific dimensions, i.e.¬†variables.\n\u0026gt; covid_ecdc %\u0026gt;% + glimpse() ## Rows: ?? ## Columns: 12 ## Database: sqlite 3.33.0 [:memory:] ## $ dateRep \u0026lt;dbl\u0026gt; 16066944‚Ä¶ ## $ day \u0026lt;dbl\u0026gt; 30, 29, ‚Ä¶ ## $ month \u0026lt;dbl\u0026gt; 11, 11, ‚Ä¶ ## $ year \u0026lt;dbl\u0026gt; 2020, 20‚Ä¶ ## $ cases \u0026lt;dbl\u0026gt; 0, 228, ‚Ä¶ ## $ deaths \u0026lt;dbl\u0026gt; 0, 11, 1‚Ä¶ ## $ countriesAndTerritories \u0026lt;chr\u0026gt; \u0026quot;Afghani‚Ä¶ ## $ geoId \u0026lt;chr\u0026gt; \u0026quot;AF\u0026quot;, \u0026quot;A‚Ä¶ ## $ countryterritoryCode \u0026lt;chr\u0026gt; \u0026quot;AFG\u0026quot;, \u0026quot;‚Ä¶ ## $ popData2019 \u0026lt;dbl\u0026gt; 38041757‚Ä¶ ## $ continentExp \u0026lt;chr\u0026gt; \u0026quot;Asia\u0026quot;, ‚Ä¶ ## $ `Cumulative_number_for_14_days_of_COVID-19_cases_per_100000` \u0026lt;dbl\u0026gt; 6.416633‚Ä¶ Before we go any further and start the analysis of covid data we will replicate the above queries using the dplyr functions. First, to illustrate how easy it is to do the column selection with dplyr we‚Äôll select countriesAndTerritories and continentExpfrom ourcovid_ecdc` data.\n\u0026gt; head(covid_ecdc %\u0026gt;% + select(countriesAndTerritories, continentExp)) # returns first six rows of the vector, i.e. tibble ## # Source: lazy query [?? x 2] ## # Database: sqlite 3.33.0 [:memory:] ## countriesAndTerritories continentExp ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Afghanistan Asia ## 2 Afghanistan Asia ## 3 Afghanistan Asia ## 4 Afghanistan Asia ## 5 Afghanistan Asia ## 6 Afghanistan Asia The First query was the count of entries for each continent.\n\u0026gt; covid_ecdc %\u0026gt;% + group_by(continentExp) %\u0026gt;% + tally() ## # Source: lazy query [?? x 2] ## # Database: sqlite 3.33.0 [:memory:] ## continentExp n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 Africa 14196 ## 2 America 13056 ## 3 Asia 12653 ## 4 Europe 16601 ## 5 Oceania 2332 ## 6 Other 64 The second was to look for the number of entries for the UK.\n\u0026gt; covid_ecdc %\u0026gt;% + filter(countriesAndTerritories == \u0026quot;United_Kingdom\u0026quot;) %\u0026gt;% + tally() ## # Source: lazy query [?? x 1] ## # Database: sqlite 3.33.0 [:memory:] ## n ## \u0026lt;int\u0026gt; ## 1 336 If you do not have to manipulate and do the engineering work with DBs, but you need to access it to obtain data for the analysis, you might find it easier to do it all using the dplyr. It is intuitive and therefore easier to write. You cannot deny that dplyr‚Äôs version also looks neater.\nNext, we‚Äôll check the total number of readings for each country and present it in a table using the DT package. DT provides an R interface to the JavaScript library DataTables, which will enable us to filter through the displayed data.\n\u0026gt; if (!require(\u0026quot;DT\u0026quot;)) install.packages(\u0026#39;DT\u0026#39;) # returns a logical value say, FALSE if the requested package is not found and TRUE if the package is loaded \u0026gt; tt \u0026lt;- covid_ecdc %\u0026gt;% + group_by(countriesAndTerritories) %\u0026gt;% + summarise(no_readings = n()) %\u0026gt;% + arrange(no_readings) \u0026gt; \u0026gt; mdt \u0026lt;- DT::datatable(data.frame(tt)) \u0026gt; widgetframe::frameWidget(mdt)  {\"x\":{\"url\":\"/post/Covid_UK/index_files/figure-html//widgets/widget_covid_ecdc.html\",\"options\":{\"xdomain\":\"*\",\"allowfullscreen\":false,\"lazyload\":false}},\"evals\":[],\"jsHooks\":[]}  Tidying Data We will focus our analysis on European countries and select them from our covid_world data, saving it all as covid_eu data frame object as this data needs tidying and wrangling and we do not want to limit ourselves by using only dplyr functions in R.\n\u0026gt; covid_eu \u0026lt;- rbind(covid_world %\u0026gt;% filter(continentExp == \u0026quot;Europe\u0026quot;), + covid_world %\u0026gt;% filter(countriesAndTerritories == \u0026quot;Turkey\u0026quot;)) \u0026gt; \u0026gt; mdt \u0026lt;- DT::datatable(covid_eu) \u0026gt; widgetframe::frameWidget(mdt)  {\"x\":{\"url\":\"/post/Covid_UK/index_files/figure-html//widgets/widget_ecdc_data.html\",\"options\":{\"xdomain\":\"*\",\"allowfullscreen\":false,\"lazyload\":false}},\"evals\":[],\"jsHooks\":[]} You can, however, try to pull the data from the server into R‚Äôs memory and by using dplyr functions do the required manipulations.\n\u0026gt; covid_eu \u0026lt;- covid_ecdc %\u0026gt;% + filter(continentExp == \u0026quot;Europe\u0026quot;) %\u0026gt;% + collect() \u0026gt; \u0026gt; mdt \u0026lt;- DT::datatable(covid_eu) \u0026gt; widgetframe::frameWidget(mdt) The experience with COVID-19 shows that the spread of the disease can be controlled by implementing the measures of prevention as soon as an outbreak has been detected.\n To monitor the effectiveness of the introduced measures we will focus on daily cumulative cases of COVID-19 infection that can be expressed as \\[F(x) = \\sum_{i=1}^{n} x_i\\]\n  Although \\(F(x)\\) can show the volume of the epidemic it does not tell us directly about the changes in the acceleration of the spread of infection. This information can be provided by the derivatives of the \\(F(x)\\). The first derivative \\(F^{‚Äô}(x)\\) corresponds to the information of the number of new cases detected every day and the second derivative \\(F^{‚Äô‚Äô}(x)\\) provides the information about the acceleration of the epidemic. \\(F^{‚Äô‚Äô}(x) \\approx 0\\) indicates the state of stagnation, while \\(F^{‚Äô‚Äô}(x) \u0026lt; 0\\) indicates deceleration and of course any \\(F^{‚Äô‚Äô}(x) \u0026gt; 0\\) acceleration.\n We will carry on with the analysis by tidying covid_eu data and adding the information about those derivatives. First, we notice that there are 4 columns used to contain the date of reporting, which will allow us to remove columns 2-4 as redundant. We will only keep the dateRep column which requires some tidying up in respect of the format in which the dates are recorded. We will also carry out the necessary calculations for obtaining the second derivative \\(F^{‚Äô‚Äô}(x)\\) and rename some of the variables to make them easier to display and type. üòÅ All of this is very easy to carry out in R using the tidy verse, opinionated collection of R packages for data science.\n\u0026gt; # --- tidy data --- \u0026gt; glimpse(covid_eu) ## Rows: 16,863 ## Columns: 12 ## $ dateRep \u0026lt;dttm\u0026gt; 2020-11‚Ä¶ ## $ day \u0026lt;dbl\u0026gt; 30, 29, ‚Ä¶ ## $ month \u0026lt;dbl\u0026gt; 11, 11, ‚Ä¶ ## $ year \u0026lt;dbl\u0026gt; 2020, 20‚Ä¶ ## $ cases \u0026lt;dbl\u0026gt; 835, 545‚Ä¶ ## $ deaths \u0026lt;dbl\u0026gt; 11, 16, ‚Ä¶ ## $ countriesAndTerritories \u0026lt;chr\u0026gt; \u0026quot;Albania‚Ä¶ ## $ geoId \u0026lt;chr\u0026gt; \u0026quot;AL\u0026quot;, \u0026quot;A‚Ä¶ ## $ countryterritoryCode \u0026lt;chr\u0026gt; \u0026quot;ALB\u0026quot;, \u0026quot;‚Ä¶ ## $ popData2019 \u0026lt;dbl\u0026gt; 2862427,‚Ä¶ ## $ continentExp \u0026lt;chr\u0026gt; \u0026quot;Europe\u0026quot;‚Ä¶ ## $ `Cumulative_number_for_14_days_of_COVID-19_cases_per_100000` \u0026lt;dbl\u0026gt; 342.1921‚Ä¶ \u0026gt; #covid_eu \u0026lt;- covid_eu[, -c(2:4)] # remove redundant information \u0026gt; covid_eu \u0026lt;- covid_eu %\u0026gt;% + separate(dateRep, c(\u0026quot;dateRep\u0026quot;), sep = \u0026quot;T\u0026quot;) %\u0026gt;% + group_by(countriesAndTerritories) %\u0026gt;% + arrange(dateRep) %\u0026gt;% + mutate(total_cases = cumsum(cases), + total_deaths = cumsum(deaths)) %\u0026gt;% + mutate(Diff_cases = total_cases - lag(total_cases), # 1st derivative (same as cases) + Rate_pc_cases = round(Diff_cases/lag(total_cases) * 100, 2)) %\u0026gt;% # rate of change + mutate(second_der = Diff_cases - lag(Diff_cases)) %\u0026gt;% # 2nd derivative + rename(country = countriesAndTerritories) %\u0026gt;% + rename(country_code = countryterritoryCode) %\u0026gt;% + rename(Fx14dper100K = \u0026quot;Cumulative_number_for_14_days_of_COVID-19_cases_per_100000\u0026quot;) %\u0026gt;% + mutate(Fx14dper100K = round(Fx14dper100K)) \u0026gt; \u0026gt; covid_eu$dateRep \u0026lt;- as.Date(covid_eu$dateRep) \u0026gt; head(covid_eu) # returns first six rows of the df ## # A tibble: 6 x 17 ## # Groups: country [6] ## dateRep day month year cases deaths country geoId country_code ## \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 2019-12-31 31 12 2019 0 0 Armenia AM ARM ## 2 2019-12-31 31 12 2019 0 0 Austria AT AUT ## 3 2019-12-31 31 12 2019 0 0 Azerba‚Ä¶ AZ AZE ## 4 2019-12-31 31 12 2019 0 0 Belarus BY BLR ## 5 2019-12-31 31 12 2019 0 0 Belgium BE BEL ## 6 2019-12-31 31 12 2019 0 0 Croatia HR HRV ## # ‚Ä¶ with 8 more variables: popData2019 \u0026lt;dbl\u0026gt;, continentExp \u0026lt;chr\u0026gt;, ## # Fx14dper100K \u0026lt;dbl\u0026gt;, total_cases \u0026lt;dbl\u0026gt;, total_deaths \u0026lt;dbl\u0026gt;, ## # Diff_cases \u0026lt;dbl\u0026gt;, Rate_pc_cases \u0026lt;dbl\u0026gt;, second_der \u0026lt;dbl\u0026gt;   Writing Functions As we would like to be able to plot this time series of the second derivatives \\(F^{‚Äô‚Äô}(x)\\) for any country we will create functions that will allow us to extract a country from the covid_eu data and to plot it as a time series.\n\u0026gt; # function for filltering a country from the given df \u0026gt; sep_country \u0026lt;- function(df, ccode){ + df_c \u0026lt;- df %\u0026gt;% + filter(country_code == as.character(ccode)) + return(df_c) + } \u0026gt; \u0026gt; # plotting the 2nd derivative \u0026gt; sec_der_plot \u0026lt;- function(df){ + df %\u0026gt;% + filter(!is.na(second_der)) %\u0026gt;% + ggplot(aes(x = dateRep, y = second_der)) + + geom_line() + geom_point(col = \u0026quot;#00688B\u0026quot;) + + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + + labs (title = \u0026quot;2nd derivative of F(x)\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) + }  Data Visualisation Once we have accessed and tidied up our data in R we can carry out the exploitative analysis using visualisation as an effective tool.\nplotly and ggplot We will start reporting by illustrating the time series of the daily number of new cases of infection and deaths. To make this plot more informative, we will create it as an interactive web graphic using the plotly library. You can explore different kinds of plotly graphs in R from https://plotly.com/r/basic-charts/ or by reading Step-by-Step Data Visualization Guideline with Plotly in R blog post.\necdc data updated on 2020-11-30\n\u0026gt; # Plot cases and deaths day-by-day \u0026gt; \u0026gt; covid_uk \u0026lt;- sep_country(covid_eu, \u0026quot;GBR\u0026quot;) \u0026gt; \u0026gt; x \u0026lt;- list(title = \u0026quot;date reported\u0026quot;) \u0026gt; \u0026gt; fig \u0026lt;- plot_ly(covid_uk, x = ~ dateRep) \u0026gt; fig \u0026lt;- fig %\u0026gt;% add_trace(y = ~cases, name = \u0026#39;cases\u0026#39;, type = \u0026#39;scatter\u0026#39;, mode = \u0026#39;lines\u0026#39;) \u0026gt; fig \u0026lt;- fig %\u0026gt;% add_trace(y = ~deaths, name = \u0026#39;deaths\u0026#39;, type = \u0026#39;scatter\u0026#39;, mode = \u0026#39;lines\u0026#39;) \u0026gt; fig \u0026lt;- fig %\u0026gt;% layout(xaxis = x) \u0026gt; fig  The plots below illustrate dynamic changes based on the \\(F(x)\\) created using the ggplot2 package. What we would like to see is the flattening of the bars indicating the slowdown in the number of new Covid-19 cases.\n\u0026gt; covid_uk %\u0026gt;% + ggplot(aes(x = dateRep, y = total_cases)) + + geom_bar(stat=\u0026quot;identity\u0026quot;, fill = \u0026quot;#00688B\u0026quot;) + + labs (title = \u0026quot;Cumulative number of cases F(x)\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;, + x = \u0026quot;Date\u0026quot;, y = \u0026quot;number of cases\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) + + theme(legend.position=\u0026quot;none\u0026quot;)  We will present the same information this time using the line plot integrating interactivity, displaying the information by using the ggplotly() function.\n\u0026gt; pl1 \u0026lt;- covid_uk %\u0026gt;% + ggplot(aes(x = dateRep, y = total_cases)) + + geom_line() + geom_point(col = \u0026quot;#00688B\u0026quot;) + + xlab(\u0026quot;Date\u0026quot;) + ylab(\u0026quot;Number of Cases\u0026quot;) + + labs (title = \u0026quot;F(x)\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) \u0026gt; pl1 The following graph presents the cumulative number of covid-19 cases using a logarithmic scale to emphasise the rate of change in a way that a linear scale does not.\n\u0026gt; pl_log \u0026lt;- covid_uk %\u0026gt;% + mutate(log_total_cases = log(total_cases)) %\u0026gt;% + ggplot(aes(x = dateRep, y = log_total_cases)) + + geom_line() + geom_point(col = \u0026quot;#00688B\u0026quot;) + + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + + labs (title = \u0026quot;F(x) on log scale\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) \u0026gt; pl_log Sometimes it might be useful to present several plots next to each other. To do this in R we apply the plot_grid() function from the cowplot package.\n\u0026gt; plot_grid(pl1, pl_log) Next we will illustrate the cumulative number of cases for all selected European countries\n\u0026gt; all_plot \u0026lt;- covid_eu %\u0026gt;% + filter(country_code %in% c(\u0026quot;GBR\u0026quot;, \u0026quot;FRA\u0026quot;, \u0026quot;DEU\u0026quot;, \u0026quot;ITA\u0026quot;, \u0026quot;ESP\u0026quot;, \u0026quot;SWE\u0026quot;)) %\u0026gt;% + filter(dateRep \u0026gt; (max(dateRep) - 21)) %\u0026gt;% + ggplot(aes(x = dateRep, y = total_cases, colour = country_code)) + + geom_line() + + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + + labs (title = \u0026quot;F(x) in the last three weeks\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) + + scale_x_date(labels = date_format(\u0026quot;%m-%d\u0026quot;), + breaks = \u0026#39;day\u0026#39;) + + scale_colour_brewer(palette = \u0026quot;Set1\u0026quot;) + + theme_classic() + + theme(legend.position = \u0026quot;bottom\u0026quot;) + + theme(axis.text.x = element_text(angle = 90))  \u0026gt; ggplotly(all_plot)  Again, this would be easier to compare using the log scale\n\u0026gt; covid_eu %\u0026gt;% + filter(country_code %in% c(\u0026quot;GBR\u0026quot;, \u0026quot;FRA\u0026quot;, \u0026quot;DEU\u0026quot;, \u0026quot;ITA\u0026quot;, \u0026quot;ESP\u0026quot;, \u0026quot;SWE\u0026quot;)) %\u0026gt;% + filter(dateRep \u0026gt; (max(dateRep) - 21)) %\u0026gt;% + mutate(log_total_cases = log(total_cases)) %\u0026gt;% + ggplot(aes(x = dateRep, y = log_total_cases, colour = country_code)) + + geom_line() + + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + + labs (title = \u0026quot;logF(x) in the last three weeks\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) + + scale_x_date(labels = date_format(\u0026quot;%m-%d\u0026quot;), + breaks = \u0026#39;day\u0026#39;) + + scale_colour_brewer(palette = \u0026quot;Set1\u0026quot;) + + theme_classic() + + theme(legend.position = \u0026quot;bottom\u0026quot;) + + theme(axis.text.x = element_text(angle = 45))  The following plot enables us to observe the change in the acceleration in relation to the governmental measures.\n\u0026gt; covid_uk %\u0026gt;% + filter(!is.na(second_der)) %\u0026gt;% + ggplot(aes(x = dateRep, y = second_der)) + + geom_line() + geom_point(col = \u0026quot;#00688B\u0026quot;) + + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + + labs (title = \u0026quot;2nd derivative of F(x) for the UK\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu\u0026quot;) + + theme_minimal() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5), + panel.grid.major.x = element_blank(), + panel.grid.minor.x = element_blank()) + + geom_vline(xintercept = as.numeric(as.Date(\u0026quot;2020-03-23\u0026quot;)), linetype = 3, colour = \u0026quot;red\u0026quot;, alpha = 0.5) + + geom_vline(xintercept = as.numeric(as.Date(\u0026quot;2020-05-10\u0026quot;)), linetype = 3, colour = \u0026quot;dodgerblue4\u0026quot;, alpha = 0.5) + + geom_vline(xintercept = as.numeric(as.Date(\u0026quot;2020-07-04\u0026quot;)), linetype = 3, colour = \u0026quot;chartreuse4\u0026quot;, alpha = 0.5) + + geom_vline(xintercept = as.numeric(as.Date(\u0026quot;2020-11-05\u0026quot;)), linetype = 3, colour = \u0026quot;red\u0026quot;, alpha = 0.5) + + annotate(geom=\u0026quot;text\u0026quot;, x=as.Date(\u0026quot;2020-03-23\u0026quot;), y = 8000, + label=\u0026quot;UK wide lockdown\u0026quot;, col = \u0026quot;red\u0026quot;) + + annotate(geom=\u0026quot;text\u0026quot;, x=as.Date(\u0026quot;2020-05-21\u0026quot;), y = 5000, + label=\u0026quot;lockdown lifting plan\u0026quot;, col = \u0026quot;dodgerblue4\u0026quot;) + + annotate(geom=\u0026quot;text\u0026quot;, x=as.Date(\u0026quot;2020-07-04\u0026quot;), y = -5000, + label=\u0026quot;wide-ranging changes\u0026quot; , col = \u0026quot;chartreuse4\u0026quot;) + + annotate(geom=\u0026quot;text\u0026quot;, x=as.Date(\u0026quot;2020-11-05\u0026quot;), y = 8000, + label=\u0026quot;UK wide lockdown\u0026quot;, col = \u0026quot;red\u0026quot;)  Let us see how these figures compare with other countries in particular France and Germany.\nFrance: \\(F^{\u0026#39;\u0026#39;}(x)\\)\n\u0026gt; covid_fr \u0026lt;- sep_country(covid_eu, \u0026quot;FRA\u0026quot;) \u0026gt; sec_der_plot(covid_fr) Germany: \\(F^{\u0026#39;\u0026#39;}(x)\\)\n\u0026gt; covid_de \u0026lt;- sep_country(covid_eu, \u0026quot;DEU\u0026quot;) \u0026gt; sec_der_plot(covid_de) Next, we are going to visualise a comparison between these three countries of the total number of deaths month by month.\n\u0026gt; covid_eu %\u0026gt;% + filter(country %in% c(\u0026quot;United_Kingdom\u0026quot;, \u0026quot;Germany\u0026quot;, \u0026quot;France\u0026quot;)) %\u0026gt;% + mutate(mon = month(dateRep, label = TRUE, abbr = TRUE)) %\u0026gt;% + group_by(country, mon) %\u0026gt;% + summarise(no_readings = n(), tdeath = max(total_deaths)) %\u0026gt;% + ggplot(aes(x = mon, y = tdeath, fill = country)) + + geom_bar(stat=\u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;, color = \u0026quot;black\u0026quot;) + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5)) + + labs (title = \u0026quot;total number of deaths by month\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu/en\u0026quot;, + x = \u0026quot;month\u0026quot;, y = \u0026quot;number of deaths\u0026quot;) + + scale_fill_brewer(palette=\u0026quot;Paired\u0026quot;) + + theme(legend.position=\u0026quot;bottom\u0026quot;)  We can make the same kind of comparisons for the total number of infections. But, before we just copy/paste and make an adjustment for y access, note that the order of the months does not show in the timeline of covid events. The recording of information about the spread of the pandemic started last December, which means that the bars should be in order from December to November. We are also going to flip the bars to see if it will add to its readability.\n\u0026gt; covid_eu %\u0026gt;% + filter(country %in% c(\u0026quot;United_Kingdom\u0026quot;, \u0026quot;Germany\u0026quot;, \u0026quot;France\u0026quot;)) %\u0026gt;% + mutate(mon = month(dateRep, label = TRUE, abbr = TRUE)) %\u0026gt;% + mutate(mon = factor(mon, levels=c(\u0026quot;Dec\u0026quot;, \u0026quot;Jan\u0026quot;, \u0026quot;Feb\u0026quot;, \u0026quot;Mar\u0026quot;, \u0026quot;Apr\u0026quot;, \u0026quot;May\u0026quot;, \u0026quot;Jun\u0026quot;, \u0026quot;Jul\u0026quot;, \u0026quot;Aug\u0026quot;, \u0026quot;Sep\u0026quot;, \u0026quot;Oct\u0026quot;, \u0026quot;Nov\u0026quot;))) %\u0026gt;% + group_by(country, mon) %\u0026gt;% + summarise(no_readings = n(), tcases = max(total_cases)) %\u0026gt;% + ggplot(aes(x = mon, y = tcases, fill = country)) + + geom_bar(stat=\u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;, color = \u0026quot;black\u0026quot;) + + coord_flip() + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5)) + + labs (title = \u0026quot;total number of infections by month\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu/en\u0026quot;, + x = \u0026quot;month\u0026quot;, y = \u0026quot;number of infections\u0026quot;) + + scale_fill_brewer(palette=\u0026quot;Set1\u0026quot;) + + theme(legend.position=\u0026quot;bottom\u0026quot;)  We can present the total number of infections for each month. As the numbers are high we are going to ‚Äúcontrol‚Äù the way the values on the y access are going to appear.\n\u0026gt; covid_eu %\u0026gt;% + filter(country %in% c(\u0026quot;United_Kingdom\u0026quot;, \u0026quot;Germany\u0026quot;, \u0026quot;France\u0026quot;)) %\u0026gt;% + mutate(mon = month(dateRep, label = TRUE, abbr = TRUE)) %\u0026gt;% + mutate(mon = factor(mon, levels=c(\u0026quot;Dec\u0026quot;, \u0026quot;Jan\u0026quot;, \u0026quot;Feb\u0026quot;, \u0026quot;Mar\u0026quot;, \u0026quot;Apr\u0026quot;, \u0026quot;May\u0026quot;, \u0026quot;Jun\u0026quot;, \u0026quot;Jul\u0026quot;, \u0026quot;Aug\u0026quot;, \u0026quot;Sep\u0026quot;, \u0026quot;Oct\u0026quot;, \u0026quot;Nov\u0026quot;))) %\u0026gt;% + group_by(country, mon) %\u0026gt;% + summarise(month_cases = sum(cases)) %\u0026gt;% + ggplot(aes(x = mon, y = month_cases, fill = country)) + + geom_bar(stat=\u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;, color = \u0026quot;black\u0026quot;) + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5)) + + scale_y_continuous(breaks = seq(0, 800000, 200000), labels = c(\u0026quot;0\u0026quot;, \u0026quot;200K\u0026quot;, \u0026quot;400K\u0026quot;, \u0026quot;600K\u0026quot;, \u0026quot;800K\u0026quot;)) + + labs (title = \u0026quot;total number of infections each month\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu/en\u0026quot;, + x = \u0026quot;month\u0026quot;, y = \u0026quot;number of deaths\u0026quot;) + + scale_fill_brewer(palette=\u0026quot;Dark2\u0026quot;) + + theme(legend.position=\u0026quot;bottom\u0026quot;)  Next, we are going to present the total number of deaths for each of the months since the recording began. Note, that in the code there is a line that is currently set as a comment that allows for the values to appear as texts on the top of the bars. You can go ahead and uncomment this line by removing the hashtag symbol in front of it.\n\u0026gt; covid_eu %\u0026gt;% + filter(country %in% c(\u0026quot;United_Kingdom\u0026quot;, \u0026quot;Germany\u0026quot;, \u0026quot;France\u0026quot;)) %\u0026gt;% + mutate(mon = month(dateRep, label = TRUE, abbr = TRUE)) %\u0026gt;% + mutate(mon = factor(mon, levels=c(\u0026quot;Dec\u0026quot;, \u0026quot;Jan\u0026quot;, \u0026quot;Feb\u0026quot;, \u0026quot;Mar\u0026quot;, \u0026quot;Apr\u0026quot;, \u0026quot;May\u0026quot;, \u0026quot;Jun\u0026quot;, \u0026quot;Jul\u0026quot;, \u0026quot;Aug\u0026quot;, \u0026quot;Sep\u0026quot;, \u0026quot;Oct\u0026quot;, \u0026quot;Nov\u0026quot;))) %\u0026gt;% + group_by(country, mon) %\u0026gt;% + summarise(month_deaths = sum(deaths)) %\u0026gt;% + ggplot(aes(x = mon, y = month_deaths, fill = country)) + + geom_bar(stat=\u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;, color = \u0026quot;black\u0026quot;) + + theme(plot.title = element_text(size = 14, vjust = 2, hjust=0.5)) + + # geom_text(aes(label = month_cases), size = 3, hjust = 0.5) + + labs (title = \u0026quot;total number of deaths each month\u0026quot;, + caption = \u0026quot;Data from: https://www.ecdc.europa.eu/en\u0026quot;, + x = \u0026quot;month\u0026quot;, y = \u0026quot;number of cases\u0026quot;) + + scale_fill_brewer(palette=\u0026quot;Accent\u0026quot;) + + theme(legend.position=\u0026quot;bottom\u0026quot;)   Spatial Visualisation We will create a choropleth in which we will colour the EU countries according to the most current value of cumulative numbers for 14 days of COVID-19 cases per 100000. To do this we will use the shape file onto which we will superimpose this value as a colour of the polygon, i.e.¬†country.\n\u0026gt; #points to the shape file \u0026gt; bound \u0026lt;- \u0026quot;shapes/eu_countries_simplified.shp\u0026quot; \u0026gt; \u0026gt; #used the st_read() function to import it \u0026gt; bound \u0026lt;- st_read(bound) ## Reading layer `eu_countries_simplified\u0026#39; from data source `/Users/Tanja1/Documents/My_R/mws/content/post/Covid_UK/shapes/eu_countries_simplified.shp\u0026#39; using driver `ESRI Shapefile\u0026#39; ## replacing null geometries with empty geometries ## Simple feature collection with 54 features and 4 fields (with 4 geometries empty) ## geometry type: GEOMETRY ## dimension: XY ## bbox: xmin: -10.48 ymin: 34.5675 xmax: 44.81861 ymax: 71.13312 ## CRS: 4326 \u0026gt; # plot the shape file \u0026gt; ggplot(bound) + + geom_sf() \u0026gt; covid_EU \u0026lt;- covid_eu %\u0026gt;% + filter(dateRep == max(dateRep)) \u0026gt; \u0026gt; \u0026gt; # tidy up \u0026gt; # make the country names correspond to ecdc data \u0026gt; bound$country \u0026lt;- gsub(\u0026quot; \u0026quot;, \u0026quot;_\u0026quot;, bound$country) \u0026gt; bound \u0026lt;- bound %\u0026gt;% + mutate(country = fct_recode(country, + \u0026quot;Czechia\u0026quot; = \u0026quot;Czech_Republic\u0026quot;, + \u0026quot;North_Macedonia\u0026quot; = \u0026quot;Macedonia\u0026quot;)) \u0026gt; \u0026gt; # join data from the two data frames \u0026gt; my_map \u0026lt;- left_join(bound, covid_EU, + by = c(\u0026quot;country\u0026quot; = \u0026quot;country\u0026quot;)) \u0026gt; \u0026gt; ggplot(my_map) + + geom_sf(aes(fill = Fx14dper100K)) + + scale_fill_distiller(direction = 1, name = \u0026quot;Fx14per100K\u0026quot;) + + labs(title=\u0026quot;Cumulative number for 14 days of COVID-19 cases per 100000\u0026quot;, caption=\u0026quot;Source: ecdc\u0026quot;) \u0026gt; mdt \u0026lt;- DT::datatable(my_map) \u0026gt; widgetframe::frameWidget(mdt)  {\"x\":{\"url\":\"/post/Covid_UK/index_files/figure-html//widgets/widget_unnamed-chunk-35.html\",\"options\":{\"xdomain\":\"*\",\"allowfullscreen\":false,\"lazyload\":false}},\"evals\":[],\"jsHooks\":[]} With the tmap package, thematic maps can be generated with great effectiveness presenting several layers of information. The syntax is similar to the one adopted in ggplot. Motivation and the explanation of this package has been proposed and published in the article tmap: Thematic Maps in R.\nIf you are interested in learning more about creating maps in R check the online version of the book Geocomputation with R. Chapter 8: The Making maps with R provides an easy to follow overview on using the tmap and other packages for creating beautiful maps in R.\n\u0026gt; my_map \u0026lt;- my_map %\u0026gt;% + mutate(ln_deaths = log(deaths)^10) \u0026gt; \u0026gt; #tmap_mode(mode = \u0026quot;view\u0026quot;) \u0026gt; \u0026gt; tm_shape(my_map) + + tm_polygons(\u0026quot;Fx14dper100K\u0026quot;, + id = \u0026quot;country\u0026quot;, + palette = \u0026quot;YlGn\u0026quot;, + popup.vars=c(\u0026quot;cases\u0026quot;, + \u0026quot;deaths\u0026quot;)) + + tm_layout(title = \u0026quot;Covid-19 EU\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;data source: \u0026lt;a href=\u0026#39;https://www.ecdc.europa.eu/en/covid-19-pandemic\u0026#39;\u0026gt;ECDC\u0026lt;/a\u0026gt;\u0026quot;, + frame = FALSE, + inner.margins = c(0.1, 0.1, 0.05, 0.05))   Lastly, we should not forget to disconnect from the database.\ndbDisconnect(SQLcon)   Useful Links  Databases using R\n SQL databases and R\n Book: Interactive web-based data visualization with R, plotly, and shiny\n   Working with a DB in R section is an adaptation of the NHS-R Community Database Connections in R webinar created and run by Chris Mainey.  ","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606694400,"objectID":"a1f7f99f7be7767dfb4c7c887d06fecb","permalink":"/post/covid_uk/","publishdate":"2020-11-30T00:00:00Z","relpermalink":"/post/covid_uk/","section":"post","summary":"Open data belongs to everyone; it empowers people to make informed decisions that are not clouded by misinformation, rumour and gossip. To be able to identify the underlying facts within data sets, it is crucial that individuals and communities possess the necessary skills.","tags":null,"title":"Covid UK: How to do it in R","type":"post"},{"authors":null,"categories":null,"content":" Thematic maps are geographical maps in which spatial data distributions are visualised. Earlier this year I contributed to the CINS‚Äô article about donations to local political parties for the period between 2012-2018. We created an interactive thematic map, choropleth, shading the development group of the town and adding two more layers of information, i.e.¬†attributes: the total amount of money donated (size and the colour of the bubble) and the amount of money received by each of the political party (popup menu)\nüîéPogledajte odakle dolaze donatori @sns_srbija @socijalisti i @demokrate i ko je prikupio najvi≈°e para od donacija u periodu od sedam godina üí∏üëáhttps://t.co/2HHXrSLSLC ‚Äî CINS (@CINSerbia) May 25, 2020   To create an interactive map like this in R you will need the tmap package. In order to provide the workflow to create thematic maps additionally you need a set of tools for reading and processing spatial data available through the tmaptools. I will illustrate how easy it is to create a thematic map using the tmap package, but you can learn more about this package from the tmap: get started! website.\nR has impressive geographic capabilities and can handle different kinds of spatial data file formats including geojson and KML. In this example we will make a use of the ESRI Shapefile format, which stores non-topological geometry and attribute information for the spatial features in a data set. A shapefile consists minimally of a main file, an index file, and a dBASE table.\n .shp - lists shape and vertices .shx - has index with offsets .dbf - relationship file between geometry and attributes (data)  To import an ESRI shapefile into R correctly, all three files must be present in the directory and named the same (except for the file extension).\nTo reproduce this example you will need to download spatial files and data that is visualised on the map. You can download this data bundle from here. These shape files with Serbian districts‚Äô boundaries are obtained from GADM maps and data.\nWe will start by uploading the required packages and read simple features from our spatial files as indicated in the code below.\n## If you don\u0026#39;t have ggplot2, dplyr, sf, sp, tm, tmaptools installed yet, uncomment and run the line below #install.packages(\u0026quot;ggplot2\u0026quot;, \u0026quot;dplyr\u0026quot;, \u0026quot;sf\u0026quot;, \u0026quot;sp\u0026quot;, \u0026quot;readxl\u0026quot;, tm\u0026quot;, \u0026quot;tmaptools\u0026quot;) library(ggplot2) library(dplyr) library(sf) library(sp) library(readxl) library(tmap) library(tmaptools) #pointed to the shape file serbia_location1 \u0026lt;- \u0026quot;spatial/gadm36_SRB_1.shp\u0026quot; #used the st_read() function to import it serbia_districts1 \u0026lt;- st_read(serbia_location1) The visualisation needs to\n indicate the development group for each of the Serbian municipality display donations to local political parties for the period between 2012-2018 for each of the municipality  Belgrade city has several municipalities, but donations to local political parties for the period between 2012-2018 is given for the whole of Belgrade. This requires to pull out the boundary for whole of the Belgrade district and to combaine it with the boundaries for the rest of Serbian municipalities.\nIn order to filter the necessary geometry for Belgrade district and to combine it with the sf data for Serbian municipalities we will use tidyverse methods for sf objects. Another issue we need to address is that data also contains information about Kosovo which needs to be included on the map. We will read shape files for Serbian and Kosovo municipalities and combine it into one.\n# filter out geometry of Belgrade\u0026#39;s district serbia_districts1 \u0026lt;- serbia_districts1 %\u0026gt;% filter(as.character(VARNAME_1) == \u0026quot;Belgrade\u0026quot;) # pointed to the shape files for municipalities (Serbia and Kosovo) serbia_location \u0026lt;- \u0026quot;gadm36_SRB_2.shp\u0026quot; kosovo_location \u0026lt;- \u0026quot;gadm36_XKO_2.shp\u0026quot; #used the st_read() function to import them serbia_districts \u0026lt;- st_read(serbia_location) kosovo_districts \u0026lt;- st_read(kosovo_location) # replace geometries of Belgrade\u0026#39;s municipalities with Belgrade district BG \u0026lt;- serbia_districts %\u0026gt;% filter(NAME_2 == \u0026quot;Stari Grad\u0026quot;) BG$NAME_2 \u0026lt;- \u0026quot;Beograd\u0026quot; BG$NL_NAME_2 \u0026lt;- BG$NL_NAME_1 BG$geometry \u0026lt;- serbia_districts1$geometry serbia_districts_BG \u0026lt;- serbia_districts %\u0026gt;% filter(NAME_1 != \u0026quot;Grad Beograd\u0026quot;) serbia_districts_BG1 \u0026lt;- rbind(BG, serbia_districts_BG) # combine sf data of serbia and Kosovo sr \u0026lt;- rbind(serbia_districts_BG1, kosovo_districts) In the next step we read data to be maped given in the Excel file and make sure that the names of the municipalities correspond to the names in the sf file old fashion way üòÅ.\n# read excel file razvijenost \u0026lt;- read_excel(\u0026quot;razvijenost.xlsx\u0026quot;, sheet = 1) ki \u0026lt;- serbia_districts$NL_NAME_2[serbia_districts$NAME_2 == \u0026quot;Kikinda\u0026quot;] gm \u0026lt;- serbia_districts$NL_NAME_2[serbia_districts$NAME_2 == \u0026quot;Gornji Milanovac\u0026quot;] ar \u0026lt;- serbia_districts$NL_NAME_2[serbia_districts$NAME_2 == \u0026quot;Arilje\u0026quot;] pe \u0026lt;- serbia_districts$NL_NAME_2[serbia_districts$NAME_2 == \u0026quot;Petrovac\u0026quot;] dm \u0026lt;- serbia_districts$NL_NAME_2[serbia_districts$NAME_2 == \u0026quot;Dimitrovgrad\u0026quot;] # ---- pr \u0026lt;- kosovo_districts$NL_NAME_2[kosovo_districts$NAME_2 == \u0026quot;Pri≈°tina\u0026quot;] ur \u0026lt;- kosovo_districts$NL_NAME_2[kosovo_districts$NAME_2 == \u0026quot;Uro≈°evac\u0026quot;] razvijenost$Town[razvijenost$Town == \u0026quot;–ö–∏–∫–∏–Ω–¥–∞\u0026quot;] \u0026lt;- ki razvijenost$Town[razvijenost$Town ==\u0026quot;–ì–æ—Ä—ö–∏ –ú–∏–ª–∞–Ω–æ–≤–∞—Ü\u0026quot;] \u0026lt;- gm razvijenost$Town[razvijenost$Town ==\u0026quot;–ê—Ä–∏—ô–µ\u0026quot;] \u0026lt;- ar razvijenost$Town[razvijenost$Town ==\u0026quot;–ü–µ—Ç—Ä–æ–≤–∞—Ü –Ω–∞ –ú–ª–∞–≤–∏\u0026quot;] \u0026lt;- pe razvijenost$Town[razvijenost$Town ==\u0026quot;–î–∏–º–∏—Ç—Ä–æ–≤–≥—Ä–∞–¥\u0026quot;] \u0026lt;- dm # ---- razvijenost$Town[razvijenost$Town ==\u0026quot;–ü—Ä–∏—à—Ç–∏–Ω–∞\u0026quot;] \u0026lt;- pr razvijenost$Town[razvijenost$Town ==\u0026quot;–£—Ä–æ—à–µ–≤–∞—Ü\u0026quot;] \u0026lt;- ur # merge data: sf and excel my_map \u0026lt;- left_join(sr, razvijenost, by=c(\u0026quot;NL_NAME_2\u0026quot; = \u0026quot;Town\u0026quot;)) Once data is organised it can be mapped using tmap. To make it aesthetically more appealing we will rescale the values for total donation so that the bubbles that are going to be used in its visualisation are not too small nor too big. Another matter that needs to be address is that polygon of Negotin‚Äôs municipality has an extra border that needs to be remove before we can map data.\n# ==================== # ----- Mapping ------ library(tmap) library(tmaptools) # scaling `donation` my_map \u0026lt;- my_map %\u0026gt;% mutate(ln_donation = log(donation)^6) # Pull out the geometry for Negotin bad_geo = my_map %\u0026gt;% filter(NAME_2 == \u0026quot;Negotin\u0026quot;) %\u0026gt;% pull(geometry) # Keep only the first of the two polygon borders good_geo = bad_geo[[1]][1] # Replace old geometry with fixed my_map$geometry[which(my_map$NAME_2 == \u0026quot;Negotin\u0026quot;)] \u0026lt;- st_multipolygon(good_geo) # set tmap mode to interactive viewing tmap_mode(mode = \u0026quot;view\u0026quot;) # shade municipalities according to the group development and superimpose bubble which size and colour shade correspond to the total level of donation. Enable pop-up information about individual party donations (show it using Latin alphabet rather than Cyrillic). tm_shape(my_map) + tm_polygons(\u0026quot;development_group\u0026quot;, id = \u0026quot;NAME_2\u0026quot;, palette = \u0026quot;YlGn\u0026quot;, title = \u0026quot;Grupa razvijenosti\u0026quot;, textNA = \u0026quot;nema podataka\u0026quot;, popup.vars=c(\u0026quot;DS\u0026quot;=\u0026quot;–î–°\u0026quot;, \u0026quot;SNS\u0026quot;=\u0026quot;–°–ù–°\u0026quot;, \u0026quot;SPS\u0026quot;=\u0026quot;–°–ü–°\u0026quot;, \u0026quot;Ukupno (RSD)\u0026quot; = \u0026quot;donation\u0026quot;)) + tm_bubbles(size = \u0026quot;ln_donation\u0026quot;, col = \u0026quot;donation\u0026quot;, border.col = \u0026quot;black\u0026quot;, border.alpha = 1, style = \u0026quot;fixed\u0026quot;, breaks=c(0 , 1000000, 10000000, 50000000, 100000000, 200000000, 500000000), palette = \u0026quot;PuRd\u0026quot;, contrast = 1, title.col = \u0026quot;Ukupno donirano u RSD\u0026quot;, id = \u0026quot;NAME_2\u0026quot;, popup.vars=c(\u0026quot;DS\u0026quot;=\u0026quot;–î–°\u0026quot;, \u0026quot;SNS\u0026quot;=\u0026quot;–°–ù–°\u0026quot;, \u0026quot;SPS\u0026quot;=\u0026quot;–°–ü–°\u0026quot;, \u0026quot;Ukupno (RSD)\u0026quot; = \u0026quot;donation\u0026quot;)) + tm_layout(legend.title.size = .5, legend.text.size = .65, legend.frame = TRUE, legend.format = list(fun = function(x) { formatC(x, digits = 0, big.mark = \u0026quot;,\u0026quot;, format = \u0026quot;f\u0026quot;) })) + tm_layout(title = \u0026quot;Prilozi graƒëana za period 2012-2018\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;izvor podataka: \u0026lt;a href=\u0026#39;http://www.acas.rs/\u0026#39;\u0026gt;ACAS\u0026lt;/a\u0026gt; i \u0026lt;a href=\u0026#39;ras.gov.rs\u0026#39;\u0026gt;RAS\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;¬© \u0026lt;a href=\u0026#39;https://www.cins.rs/\u0026#39;\u0026gt;CINS\u0026lt;/a\u0026gt;, maj 2020\u0026quot;, frame = FALSE, inner.margins = c(0.1, 0.1, 0.05, 0.05))   This is information rich visualisation. It incorporates an interactive thematic map, choropleth, shading the development group of the town and adding two more layers of information, i.e.¬†attributes: the total amount of money donated (size and the colour of the bubble) and the amount of money received by each of the political party (popup menu).\nIncorporating interactive visualisation with clearly presented facts, helped to empower readers by informing them in an effective manner.\nThis was an excellent example of effective data journalism, employed as a direct result of CINS embracing the capacity of the RToolbox.\n","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590624000,"objectID":"6f8d97042a80b89659bf6787e0963c4a","permalink":"/post/cins_map/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/post/cins_map/","section":"post","summary":"Thematic maps are geographical maps in which spatial data distributions are visualised. Earlier this year I contributed to the CINS‚Äô article about donations to local political parties for the period between 2012-2018.","tags":null,"title":"Thematic Maps","type":"post"},{"authors":null,"categories":null,"content":" There is no a definitive way for carrying out data analysis. It rather depends on the study domain and the insights you wish to extract from the data that you can collect.\nThis post is an ongoing covid-19 data journey that illustrates the behaviour of Covid-19 pandemic within the Republic of Serbia and neighbouring ex-YU countries. All of the report is created with R and is presented on its‚Äô designated website \u0026lt; https://covid19sr.rbind.io/\u0026gt; built with üíô using the blogdown and Air HUGO theme.\n","date":1586476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586476800,"objectID":"27d1dd6baaec121ce5d5727005cbed9f","permalink":"/post/covid_sr/","publishdate":"2020-04-10T00:00:00Z","relpermalink":"/post/covid_sr/","section":"post","summary":"There is no a definitive way for carrying out data analysis. It rather depends on the study domain and the insights you wish to extract from the data that you can collect.","tags":null,"title":"Covid SR: data visualisation","type":"post"},{"authors":null,"categories":null,"content":"       R Markdown For patients critically ill with COVID-19, access to a ventilator could be a matter of life or death. In early March at the beginning of COVID-19 pandemic the Serbian government was not disclosing the information about the available number of ventilators to its citizens. CINS‚Äô journalists took the initiative to obtain this information and to make it available to the public in an article concerning respiratory equipment in the current crisis. Shortly after, the government took more serious action towards protecting its citizens against the virus.\nAs a data scientist I was happy and pleased to help and assist CINS‚Äô journalist‚Äôs in making interactive maps informing readers of their findings.\nThis article can be found at https://www.cins.rs/en/coronavirus-see-how-many-medical-ventilators-there-are-in-your-town/\nTo create an interactive map like this in R you will need the leaflet package. Leaflet is one of the most popular open-source JavaScript libraries for interactive maps that was integrated into R, by a team of people from RStudio. We will illustrate how easy it is to plot a location map using the leaflet package, but you can learn more about this package from the Leaflet for R website.\nHere is what we did.\nlibrary(leaflet) suppressPackageStartupMessages(library(dplyr)) suppressPackageStartupMessages(library(tidyverse)) mydata \u0026lt;- read.csv(\u0026#39;Gradovi.csv\u0026#39;, header=T, na.strings=c(\u0026quot;\u0026quot;,\u0026quot;NA\u0026quot;), stringsAsFactor = FALSE) glimpse(mydata) ## Rows: 69 ## Columns: 7 ## $ Mesta \u0026lt;chr\u0026gt; \u0026quot;Baƒçka Topola\u0026quot;, \u0026quot;Subotica\u0026quot;, \u0026quot;Kikinda\u0026quot;, \u0026quot;Senta\u0026quot;, \u0026quot;Zrenja‚Ä¶ ## $ Latitude \u0026lt;dbl\u0026gt; 45.81442, 46.10055, 45.82728, 45.92601, 45.38156, 45.77‚Ä¶ ## $ Longitude \u0026lt;dbl\u0026gt; 19.63796, 19.66506, 20.46152, 20.07809, 20.36857, 19.11‚Ä¶ ## $ Koristi.se \u0026lt;int\u0026gt; 1, 19, 6, 6, 13, 14, 3, 1, 4, 14, 98, 48, 1, 1, 0, 16, ‚Ä¶ ## $ Ne.koristi.se \u0026lt;int\u0026gt; 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 5, 8, 0, 0, 1, 0, 0, 0, 0‚Ä¶ ## $ Nepoznato \u0026lt;int\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶ ## $ Ukupno \u0026lt;int\u0026gt; 1, 19, 6, 7, 13, 14, 3, 1, 6, 14, 103, 56, 1, 1, 1, 16,‚Ä¶ minlat \u0026lt;- min(mydata$Latitude) maxlat \u0026lt;- max(mydata$Latitude) minlng \u0026lt;- min(mydata$Longitude) maxlng \u0026lt;- max(mydata$Longitude) mydata %\u0026gt;% leaflet() %\u0026gt;% addTiles() %\u0026gt;% fitBounds(~minlng, ~minlat, ~maxlng, ~maxlat) %\u0026gt;% addCircles(lng = ~Longitude, lat = ~Latitude, radius = 750, weight = 7, color = \u0026quot;black\u0026quot;, fillColor = \u0026quot;red\u0026quot;, fillOpacity = 0.7, popup = ~paste(\u0026quot;\u0026lt;b\u0026gt;\u0026quot;, Mesta, \u0026quot;\u0026lt;/b\u0026gt;\u0026quot;, \u0026quot;\u0026lt;br\u0026gt;Koristi se = \u0026quot;, Koristi.se,\u0026quot;\u0026lt;br\u0026gt;Ne koristi se = \u0026quot;, Ne.koristi.se, \u0026quot;\u0026lt;br\u0026gt; Nepoznato =\u0026quot;, Nepoznato, \u0026quot;\u0026lt;br\u0026gt;Total =\u0026quot;, Ukupno, \u0026quot;\u0026lt;br\u0026gt;\u0026quot;))  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addCircles\",\"args\":[[45.8144238,46.1005467,45.8272842,45.9260128,45.3815612,45.773295,44.9018213,45.1071651,45.1181926,44.874,45.2671352,45.2208633,45.6138162,45.415745,45.2497275,45.5701534,45.0485391,45.00806,45.1287251,45.1011851,44.9794968,44.6034915,44.786568,44.5313463,44.7488612,44.2743141,44.367191,44.6658941,44.37366517,44.4766526,44.6208353,44.3082168,44.0127932,44.24984,43.858616,43.9777294,43.925537,44.0698918,44.6035552,44.2288747,44.4191965,43.9015048,43.5660829,43.9705397,43.4676913,45.8461,43.5827565,43.2741145,43.8555729,43.7504777,43.5827565,43.3893574,43.8555729,43.8914144,44.0207262,43.1406976,43.7238483,43.5763232,43.3209022,43.5409901,43.2367913,43.0638347,43.1557012,42.9963758,42.5450345,42.6907233,42.3091712,42.8913909,42.6014008],[19.6379551,19.6650593,20.4615173,20.0780937,20.3685737,19.1151469,21.4232908,20.6595515,21.2944883,20.6475673,19.8335496,19.8470699,20.0459853,19.8931066,19.3967698,19.6449683,20.0808092,19.82222,19.7897422,19.8616812,19.6209662,20.45241,20.4489216,19.2067663,19.6907882,19.8903398,20.9604515,20.9335169,21.41833166,21.6742577,21.1842054,20.5562765,20.9114225,21.2008216,21.403911,21.2572719,21.3748327,22.0985086,22.6098737,22.5310674,21.9495234,22.2738011,22.2466754,19.5649108,19.8125507,20.0365,19.5266606,20.0032054,19.842471,19.7142007,19.5266606,19.6463666,19.842471,20.3501652,20.4633133,20.5213617,20.6872542,21.3335812,21.8957589,21.7183695,21.5915831,22.4061647,22.5856811,21.944034,21.9002712,22.1720303,21.6498686,20.8659995,21.1918761],750,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":\"black\",\"weight\":7,\"opacity\":0.5,\"fill\":true,\"fillColor\":\"red\",\"fillOpacity\":0.7},[\" Baƒçka Topola  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Subotica  Koristi se = 19 Ne koristi se = 0 Nepoznato = 0 Total = 19 \",\" Kikinda  Koristi se = 6 Ne koristi se = 0 Nepoznato = 0 Total = 6 \",\" Senta  Koristi se = 6 Ne koristi se = 1 Nepoznato = 0 Total = 7 \",\" Zrenjanin  Koristi se = 13 Ne koristi se = 0 Nepoznato = 0 Total = 13 \",\" Sombor  Koristi se = 14 Ne koristi se = 0 Nepoznato = 0 Total = 14 \",\" Bela Crkva  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Kovaƒçica  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Vr≈°ac  Koristi se = 4 Ne koristi se = 2 Nepoznato = 0 Total = 6 \",\" Panƒçevo  Koristi se = 14 Ne koristi se = 0 Nepoznato = 0 Total = 14 \",\" Novi Sad  Koristi se = 98 Ne koristi se = 5 Nepoznato = 6 Total = 103 \",\" Sremska Kamenica  Koristi se = 48 Ne koristi se = 8 Nepoznato = 0 Total = 56 \",\" Beƒçej  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Temerin  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Baƒçka Palanka  Koristi se = 0 Ne koristi se = 1 Nepoznato = 0 Total = 1 \",\" Vrbas  Koristi se = 16 Ne koristi se = 0 Nepoznato = 0 Total = 16 \",\" Inƒëija  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Ruma  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Vrdnik  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Irig  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Sremska Mitrovica  Koristi se = 8 Ne koristi se = 1 Nepoznato = 0 Total = 9 \",\" Barajevo  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Beograd  Koristi se = 430 Ne koristi se = 30 Nepoznato = 0 Total = 460 \",\" Loznica  Koristi se = 5 Ne koristi se = 1 Nepoznato = 0 Total = 6 \",\" ≈†abac  Koristi se = 5 Ne koristi se = 1 Nepoznato = 0 Total = 6 \",\" Valjevo  Koristi se = 9 Ne koristi se = 0 Nepoznato = 0 Total = 9 \",\" Smederevska Palanka  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Smederevo  Koristi se = 10 Ne koristi se = 0 Nepoznato = 0 Total = 10 \",\" Petrovac  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" Kuƒçevo  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Po≈æarevac  Koristi se = 8 Ne koristi se = 0 Nepoznato = 0 Total = 8 \",\" Aranƒëelovac  Koristi se = 4 Ne koristi se = 0 Nepoznato = 0 Total = 4 \",\" Kragujevac  Koristi se = 35 Ne koristi se = 2 Nepoznato = 3 Total = 40 \",\" Svilajnac  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Paraƒáin  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Jagodina  Koristi se = 4 Ne koristi se = 0 Nepoznato = 0 Total = 4 \",\" ƒÜuprija  Koristi se = 7 Ne koristi se = 2 Nepoznato = 0 Total = 9 \",\" Bor  Koristi se = 3 Ne koristi se = 2 Nepoznato = 0 Total = 5 \",\" Kladovo  Koristi se = 1 Ne koristi se = 1 Nepoznato = 0 Total = 2 \",\" Negotin  Koristi se = 2 Ne koristi se = 1 Nepoznato = 0 Total = 3 \",\" Majdanpek  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" Zajeƒçar  Koristi se = 8 Ne koristi se = 0 Nepoznato = 0 Total = 8 \",\" Knja≈æevac  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Bajina Ba≈°ta  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Nova Varo≈°  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Po≈æega  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Priboj  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Sjenica  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" U≈æice  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" ƒåajetina  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Priboj  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" Prijepolje  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" U≈æice  Koristi se = 10 Ne koristi se = 3 Nepoznato = 0 Total = 13 \",\" ƒåaƒçak  Koristi se = 16 Ne koristi se = 1 Nepoznato = 0 Total = 17 \",\" Gornji Milanovac  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Novi Pazar  Koristi se = 3 Ne koristi se = 0 Nepoznato = 0 Total = 3 \",\" Kraljevo  Koristi se = 10 Ne koristi se = 0 Nepoznato = 0 Total = 10 \",\" Kru≈°evac  Koristi se = 6 Ne koristi se = 0 Nepoznato = 0 Total = 6 \",\" Ni≈°  Koristi se = 43 Ne koristi se = 2 Nepoznato = 0 Total = 45 \",\" Aleksinac  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Prokuplje  Koristi se = 4 Ne koristi se = 6 Nepoznato = 0 Total = 4 \",\" Babu≈°nica  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Pirot  Koristi se = 7 Ne koristi se = 0 Nepoznato = 0 Total = 7 \",\" Leskovac  Koristi se = 7 Ne koristi se = 0 Nepoznato = 0 Total = 7 \",\" Vranje  Koristi se = 13 Ne koristi se = 0 Nepoznato = 0 Total = 13 \",\" Surdulica  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \",\" Pre≈°evo  Koristi se = 2 Ne koristi se = 0 Nepoznato = 0 Total = 2 \",\" Kosovska Mitrovica  Koristi se = 7 Ne koristi se = 2 Nepoznato = 0 Total = 9 \",\" Graƒçanica  Koristi se = 1 Ne koristi se = 0 Nepoznato = 0 Total = 1 \"],null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null,null]}],\"fitBounds\":[42.3091712,19.1151469,46.1005467,22.6098737,[]],\"limits\":{\"lat\":[42.3091712,46.1005467],\"lng\":[19.1151469,22.6098737]}},\"evals\":[],\"jsHooks\":[]} This was data democracy in action, a means of holding governments to account and nudging them into action. By empowering citizens to be data literate they are able to cut through the fog of misinformation and to have a deeper understanding of the world we live in. There‚Äôs no need for everyone to be data scientist, but there is an urgent need for dataliteracy to be available to everyone. Data is democracy.\n ","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585267200,"objectID":"2a055bfd31aa7f717bafa8d5d89ac9ca","permalink":"/post/ventilators/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/post/ventilators/","section":"post","summary":"R Markdown For patients critically ill with COVID-19, access to a ventilator could be a matter of life or death. In early March at the beginning of COVID-19 pandemic the Serbian government was not disclosing the information about the available number of ventilators to its citizens.","tags":null,"title":"Coronavirus: See How Many Medical Ventilators There Are in Your Town","type":"post"},{"authors":null,"categories":null,"content":" Earlier in March we run our first ever Open Heroines event here in Belgrade.\nWe got things started by creating a website publicising our event and making it clear from the get go what the participants could expect from the event. The website was created in RStudio using the blogdown and HUGO and deployed using GitHub and Netlify. The responses to the site were very positive and we were particularly bowled over by the wide range of backgrounds of the people wishing to attend. From economists to journalists, students to CEO‚Äôs, the desire to understand more about the power of data acted as the adhesive to the collective ensemble\nWe illustrated the process of the democratisation of open data. In the belief that we should use a topical subject for analysis, we looked at data related to air pollution in Belgrade sourced from Vazduh Gradjanima ‚Äì a hot talking point within the city. We created R-Markdown reports where the participants created visual data reporting of the core issues connected to air pollution. There was an amazing response to everyone being able to learn how to interact with data, as if a new world was now available to them.\nIn the spirit of transparency and reproducibility for those who were not fortunate to join us in learning how to use R and analyse this air pollution data, we uploaded our findings to the GitHub https://tanjakec.github.io/OH_workshop/OHSA.html.\n","date":1584662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584662400,"objectID":"e321cf3d79a71202c36db7be12ff1748","permalink":"/post/oh/","publishdate":"2020-03-20T00:00:00Z","relpermalink":"/post/oh/","section":"post","summary":"Earlier in March we run our first ever Open Heroines event here in Belgrade.\nWe got things started by creating a website publicising our event and making it clear from the get go what the participants could expect from the event.","tags":null,"title":"Air pollution in Belgrade","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"   Click on the PDF button above to view the slides.   ","date":1529193600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529193600,"objectID":"6d69f3fcb3a9dbfec6398310ef467e41","permalink":"/talk/erum2020/","publishdate":"2020-06-18T00:00:00Z","relpermalink":"/talk/erum2020/","section":"talk","summary":"This study examines the often-tricky process of delivering data literacy programmes to professionals with most to gain from a deeper understanding of data analysis. As such, the author discusses the process of building and delivering training strategies to journalists in regions where press freedom is constrained by numerous factors, not least of all institutionalised corruption. Reporting stories that are supplemented with transparent procedural systems are less likely to be contradicted and challenged by vested interest actors. Journalists are able to present findings supported by charts and info graphics, but these are open to translation. Therefore, most importantly, the data and code of the applied analytical methodology should also be available for scrutiny and is less likely to be subverted or prohibited.As part of creating an accessible programme geared to acquiring skills necessary for data journalism, the author takes a step-by-step approach to discussing the actualities of building online platforms for training purposes. Through the use of grammar of graphics in R and Shiny, a web application framework for R, it is possible to develop interactive applications for graphical data visualisation. Presenting findings through interactive and accessible visualisation methods in a transparent and reproducible way is an effective form of reaching audiences that might not otherwise realise the value of the topic or data at hand. The resulting ‚Äòdata toolbox for journalists‚Äô is an accessible open-source resource. It can also be adapted to accommodate the need to provide a deeper understanding of the potential for data proficiency to other professions. The accessibility of R allows for users to build support communities, which in the case of journalists is essential for information gathering. Establishing and implementing transparent channels of communication is the key to scrupulous journalism and is why R is so applicable to this objective.","tags":["rstats","data journalism"],"title":"Transparent Journalism Through the Power of R","type":"talk"},{"authors":null,"categories":null,"content":"   Click on the PDF button above to view the slides.   ","date":1526256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526256000,"objectID":"3ecfa0eadad9522d1eeab32434a2efa4","permalink":"/talk/erum2018/","publishdate":"2018-05-16T00:00:00Z","relpermalink":"/talk/erum2018/","section":"talk","summary":"Setting up the computer environment for all participants of an R workshop can be a daunting and exasperating task. Installing and setting up the softwares and obtaining necessary files could give a confusing tone right at the beginning of the workshop before you have even started with the programme delivery. Not messing up with setup and being able to start using R in the same fashion as other people in the group is desirable not just to the workshop participants, but to the instructor. There are a few options available for setting up RStudio in a browser. Using RStudio Server enables you to setup working environment tailored to your specific audience. It helps by removing any frustrations for the participants caused by downloads of the required files and installations from other workshop activities that you really want them to focus on. Setting up RStudio Server on Amazon Web Service (ASW), called an EC2 (Elastic Compute Cloud) instance, is not difficult. You can customise the working environment to meet your needs by installing globally required packages, adding the data and the script files you want participants to have available when running RStudio in their browsers. Another alternative that has become recently available is RStudio Cloud. Although RStudio Cloud is an alpha version and it is still under development you could already do pretty much everything you are able by setting up your own RStudio Server. This talk will illustrate the possibilities and benefits of using RStudio in a browser that could provide a great environment for teaching and learning data science with R.","tags":["rstats","cloud","RStudio","AWS"],"title":"Data Landscapes$\\colon$ a pragmatic and philosophical visualisation of the sustainable urban landscape","type":"talk"},{"authors":null,"categories":null,"content":"  The R language provides a rich and flexible environment for working with data, especially data to be used for statistical modelling or graphics.\n R is a comprehensive public domain language for data analysis, with no licensing costs associated with it.\n Being independent of any platform, R is universally applicable and simple to integrate into existing IT structures.\n  You can download R for free from:\nhttps://cran.r-project.org/\nand RStudio, a free and open-source integrated development environment (IDE) for R\nhttps://www.rstudio.com/\nData Science  The new vast amount of data we have begun to take more and more notice of, has given a rise to the new discipline of data science.\n Growing demand of data volume and easy understandability of extracted knowledge and insights from data is the motivating force of data science.\n With the explosion of ‚ÄúBig Data‚Äù problems, data science has become a very hot field in many scientific areas as well as marketing, finance, and other business and social study disciplines. Hence, there is a growing demand for business and social scientific researchers with statistical, modelling and computing skills.\n We can now identify patterns and regularities in data of all sorts that allow us to advance scholarship, improve the human condition, and create commercial and social value.\n The field of data science is emerging at the intersection of the fields of statistics, computer science and design. R provides grate platform for this multidisciplinarity. It is incredibly powerful and as such it should be the first language for data manipulation, data analysis and visualisation you‚Äôre looking to grow skills in if you want to move towards data science.\n   Why R? The R system has an extensive library of packages that offer state-of-the-art-abilities.\nMany of the analyses that they offer are not even available in any of the standard packages.\n The functionalities of:\n   data manipulation, data analysis and visualisation implemented in R are incomparable.  R enables you to escape from the restrictive environments and sterile analyses offered by commonly used statistical software packages.\n R enables easy experimentation and exploration, which improves data analysis.\n R is a tool behind reporting modern data analyses in a reproducible manner making an analysis more useful to others because the data and code that actually conducted the analysis can be made available.\n   R Community ‚ÄúThe R community is one of R‚Äôs best features!‚Äù Revolutions Daily news about using open source R\n Supported by the R Foundation for Statistical Computing and with the strong and open engagement of developers and users from all walks of background from science to commerce it is hard to envisage that any commercial corporation will be able to develop sustainable business model with the same innovative drive and power as R community.\n The collaboration amongst statisticians and other scientist who are engaged with statistical computing and growing interest and engagement of large companies creates altruistic R community which generates the force within which R is conquering the field of data analytics. As a result it creates a more powerful R resource and becomes more usable and attractive to Data scientists and analysists.\n  List of resources ROpenSci: ‚ÄúR community is not just for ‚Äòpower users‚Äô or developers. It‚Äôs a place for users and people interested in learning more about R‚Äù; Provides list of useful links:\n#rstats hashtag ‚Äî a responsive, welcoming, and inclusive community of R users to interact with on Twitter\nR-Ladies ‚Äî a world-wide organization focused on promoting gender diversity within the R community, with more than 30 local chapters\nLocal R meetup groups ‚Äî a google search may show that there‚Äôs one in your area! If not, maybe consider starting one! Face-to-face meet-ups for users of all levels are incredibly valuable\nRweekly ‚Äî an incredible weekly recap of all things R\nR-bloggers ‚Äî an awesome resource to find posts from many different bloggers using R\nDataCarpentry and Software Carpentry ‚Äî a resource of openly available lessons that promote and model reproducible research\nStack Overflow ‚Äî chances are your R question has already been answered here (with additional resources for people looking for jobs)\n  Who uses R? Some of the major domains using R include:\n Financial Services, Pharmaceuticals, Telecom, Life Sciences and Education sector.  Top companies using R are :\n Google, LinkedIn, Facebook, The Financial Times: Quantitative Journalism, Amazon and many more‚Ä¶   How do we do it? Tools needed in a typical data science project:\nR for Data Science by Garrett Grolemund \u0026amp; Hadley Wickham\nhttp://r4ds.had.co.nz/index.html.\n Real Example Does declawing (onychectomy) cause harm to cats? Analyzing 17 years‚Äô worth of shelter admissions data. - The dataset captures specifics about the individual cat (declawed status, age, breed, coat color, etc.) as well as the primary reason for admission. Some of the admission reasons are unconnected to the animal (e.g., moving, can‚Äôt afford pet, allergies) ‚Äî but some reasons are based on problematic behaviors exhibited by the cat (e.g., house-soiling, aggressive to other animals, aggressive to people). Available to us is a CSV file containing 200 sample records.\nCat_Data\n  Do it in R # Install and load packages and data # The tidyverse is a collection of R packages designed for data science # Install the complete tidyverse with # install.packages(\u0026quot;tidyverse\u0026quot;) # load the complete tidyverse with library(tidyverse) ## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ ## ‚úì ggplot2 3.3.1 ‚úì purrr 0.3.4 ## ‚úì tibble 3.0.1 ‚úì dplyr 1.0.2 ## ‚úì tidyr 1.1.0 ‚úì stringr 1.4.0 ## ‚úì readr 1.3.1 ‚úì forcats 0.5.0 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() # Install and load the ggplot2 package: grammer of graphics # Install and load the magick package fo advanced image-processing in R # install.packages(\u0026quot;magick\u0026quot;) library(magick) ## Linking to ImageMagick 6.9.11.32 ## Enabled features: cairo, fontconfig, freetype, lcms, pango, rsvg, webp ## Disabled features: fftw, ghostscript, x11 # load the data saved on your computer # cat_claw \u0026lt;- read.csv(\u0026quot;declawing_data_sample.csv\u0026quot;) # or load the data directly from the website cat_claw \u0026lt;- read.csv(\u0026quot;declawing_data_sample.csv\u0026quot;) # Have a look at the data: head() # let us look at first three raws of the data head(cat_claw, n = 3) ## Animal.ID Animal.Name Species Gender Date.Of.Birth Primary.Breed ## 1 1032415 HARLEY Cat M 9/18/1999 Domestic Shorthair ## 2 1032962 TRUCKER Cat M 4/10/1998 Domestic Shorthair ## 3 1033799 Cat M 2/2/2000 Domestic Longhair ## Secondary.Breed Declawed Distinguishing.Markings Purebred BodyWeight ## 1 Mix None 0 0 ## 2 Mix None 0 0 ## 3 Mix None 0 2 ## BodyWeightUnit PrimaryColor SecondaryColor ColorPattern Intake.Date ## 1 \u0026lt;NA\u0026gt; Black White \u0026lt;NA\u0026gt; 03/18/2000 00:14:00 ## 2 \u0026lt;NA\u0026gt; Grey \u0026lt;NA\u0026gt; Tiger 04/06/2000 00:45:00 ## 3 pound Black \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 05/02/2000 00:37:00 ## Intake.Type Intake.Subtype Reason Reason.Category ## 1 Owner/Guardian Surrender Schedule \u0026lt;NA\u0026gt; ## 2 Stray Walk In \u0026lt;NA\u0026gt; ## 3 Owner/Guardian Surrender Walk In Too Many Pets Owner problem # Have alook at the structure of the data: str() # look at the structure of the data str(cat_claw) ## \u0026#39;data.frame\u0026#39;: 200 obs. of 20 variables: ## $ Animal.ID : int 1032415 1032962 1033799 1033965 1038328 1048494 1052572 1053299 1054811 1057979 ... ## $ Animal.Name : chr \u0026quot;HARLEY\u0026quot; \u0026quot;TRUCKER\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; ... ## $ Species : chr \u0026quot;Cat\u0026quot; \u0026quot;Cat\u0026quot; \u0026quot;Cat\u0026quot; \u0026quot;Cat\u0026quot; ... ## $ Gender : chr \u0026quot;M\u0026quot; \u0026quot;M\u0026quot; \u0026quot;M\u0026quot; \u0026quot;M\u0026quot; ... ## $ Date.Of.Birth : chr \u0026quot;9/18/1999\u0026quot; \u0026quot;4/10/1998\u0026quot; \u0026quot;2/2/2000\u0026quot; \u0026quot;3/7/2000\u0026quot; ... ## $ Primary.Breed : chr \u0026quot;Domestic Shorthair\u0026quot; \u0026quot;Domestic Shorthair\u0026quot; \u0026quot;Domestic Longhair\u0026quot; \u0026quot;Domestic Longhair\u0026quot; ... ## $ Secondary.Breed : chr \u0026quot;Mix\u0026quot; \u0026quot;Mix\u0026quot; \u0026quot;Mix\u0026quot; \u0026quot;Mix\u0026quot; ... ## $ Declawed : chr \u0026quot;None\u0026quot; \u0026quot;None\u0026quot; \u0026quot;None\u0026quot; \u0026quot;None\u0026quot; ... ## $ Distinguishing.Markings: chr \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; ... ## $ Purebred : int 0 0 0 0 0 0 0 0 0 0 ... ## $ BodyWeight : num 0 0 2 0 0 0 0 12 0 0 ... ## $ BodyWeightUnit : chr NA NA \u0026quot;pound\u0026quot; NA ... ## $ PrimaryColor : chr \u0026quot;Black\u0026quot; \u0026quot;Grey\u0026quot; \u0026quot;Black\u0026quot; \u0026quot;Orange\u0026quot; ... ## $ SecondaryColor : chr \u0026quot;White\u0026quot; NA NA \u0026quot;White\u0026quot; ... ## $ ColorPattern : chr NA \u0026quot;Tiger\u0026quot; NA NA ... ## $ Intake.Date : chr \u0026quot;03/18/2000 00:14:00\u0026quot; \u0026quot;04/06/2000 00:45:00\u0026quot; \u0026quot;05/02/2000 00:37:00\u0026quot; \u0026quot;05/07/2000 00:26:00\u0026quot; ... ## $ Intake.Type : chr \u0026quot;Owner/Guardian Surrender\u0026quot; \u0026quot;Stray\u0026quot; \u0026quot;Owner/Guardian Surrender\u0026quot; \u0026quot;Owner/Guardian Surrender\u0026quot; ... ## $ Intake.Subtype : chr \u0026quot;Schedule\u0026quot; \u0026quot;Walk In\u0026quot; \u0026quot;Walk In\u0026quot; \u0026quot;Walk In\u0026quot; ... ## $ Reason : chr \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;Too Many Pets\u0026quot; \u0026quot;Too Many Pets\u0026quot; ... ## $ Reason.Category : chr NA NA \u0026quot;Owner problem\u0026quot; \u0026quot;Owner problem\u0026quot; ... # Do it in a tidy way: glimpse() # previous output was messy as it didn\u0026#39;t fit on the slide. # we want tolook at the structure of the data as much data # as possible and identify data types for each of the variables glimpse(cat_claw) ## Rows: 200 ## Columns: 20 ## $ Animal.ID \u0026lt;int\u0026gt; 1032415, 1032962, 1033799, 1033965, 1038328, ‚Ä¶ ## $ Animal.Name \u0026lt;chr\u0026gt; \u0026quot;HARLEY\u0026quot;, \u0026quot;TRUCKER\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;PUDDY TAT\u0026quot;,‚Ä¶ ## $ Species \u0026lt;chr\u0026gt; \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Ca‚Ä¶ ## $ Gender \u0026lt;chr\u0026gt; \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, ‚Ä¶ ## $ Date.Of.Birth \u0026lt;chr\u0026gt; \u0026quot;9/18/1999\u0026quot;, \u0026quot;4/10/1998\u0026quot;, \u0026quot;2/2/2000\u0026quot;, \u0026quot;3/7/20‚Ä¶ ## $ Primary.Breed \u0026lt;chr\u0026gt; \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;‚Ä¶ ## $ Secondary.Breed \u0026lt;chr\u0026gt; \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mi‚Ä¶ ## $ Declawed \u0026lt;chr\u0026gt; \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;Fron‚Ä¶ ## $ Distinguishing.Markings \u0026lt;chr\u0026gt; \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;‚Ä¶ ## $ Purebred \u0026lt;int\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶ ## $ BodyWeight \u0026lt;dbl\u0026gt; 0.00, 0.00, 2.00, 0.00, 0.00, 0.00, 0.00, 12.‚Ä¶ ## $ BodyWeightUnit \u0026lt;chr\u0026gt; NA, NA, \u0026quot;pound\u0026quot;, NA, NA, NA, NA, \u0026quot;pound\u0026quot;, NA,‚Ä¶ ## $ PrimaryColor \u0026lt;chr\u0026gt; \u0026quot;Black\u0026quot;, \u0026quot;Grey\u0026quot;, \u0026quot;Black\u0026quot;, \u0026quot;Orange\u0026quot;, \u0026quot;Black\u0026quot;, ‚Ä¶ ## $ SecondaryColor \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, NA, NA, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Brown\u0026quot;, N‚Ä¶ ## $ ColorPattern \u0026lt;chr\u0026gt; NA, \u0026quot;Tiger\u0026quot;, NA, NA, NA, \u0026quot;Tiger\u0026quot;, \u0026quot;Tortoisesh‚Ä¶ ## $ Intake.Date \u0026lt;chr\u0026gt; \u0026quot;03/18/2000 00:14:00\u0026quot;, \u0026quot;04/06/2000 00:45:00\u0026quot;,‚Ä¶ ## $ Intake.Type \u0026lt;chr\u0026gt; \u0026quot;Owner/Guardian Surrender\u0026quot;, \u0026quot;Stray\u0026quot;, \u0026quot;Owner/G‚Ä¶ ## $ Intake.Subtype \u0026lt;chr\u0026gt; \u0026quot;Schedule\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, ‚Ä¶ ## $ Reason \u0026lt;chr\u0026gt; \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Too Many Pets\u0026quot;, \u0026quot;Too Many Pets\u0026quot;, \u0026quot;\u0026quot;,‚Ä¶ ## $ Reason.Category \u0026lt;chr\u0026gt; NA, NA, \u0026quot;Owner problem\u0026quot;, \u0026quot;Owner problem\u0026quot;, NA,‚Ä¶ What to focus on? # Note that variable \u0026#39;Declawed\u0026#39; is the main variable of interest # with three possible outcomes summary(cat_claw$Declawed) ## Length Class Mode ## 200 character character # sort the dates (DOB and InatekD) to be in the same format cat_claw$Date.Of.Birth \u0026lt;- as.Date(cat_claw$Date.Of.Birth, format=\u0026#39;%m/%d/%Y\u0026#39;) cat_claw$Intake.Date \u0026lt;- as.Date(cat_claw$Intake.Date, format=\u0026#39;%m/%d/%Y\u0026#39;) # How does it look? # check the data glimpse(cat_claw) ## Rows: 200 ## Columns: 20 ## $ Animal.ID \u0026lt;int\u0026gt; 1032415, 1032962, 1033799, 1033965, 1038328, ‚Ä¶ ## $ Animal.Name \u0026lt;chr\u0026gt; \u0026quot;HARLEY\u0026quot;, \u0026quot;TRUCKER\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;PUDDY TAT\u0026quot;,‚Ä¶ ## $ Species \u0026lt;chr\u0026gt; \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Ca‚Ä¶ ## $ Gender \u0026lt;chr\u0026gt; \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, ‚Ä¶ ## $ Date.Of.Birth \u0026lt;date\u0026gt; 1999-09-18, 1998-04-10, 2000-02-02, 2000-03-‚Ä¶ ## $ Primary.Breed \u0026lt;chr\u0026gt; \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;‚Ä¶ ## $ Secondary.Breed \u0026lt;chr\u0026gt; \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mi‚Ä¶ ## $ Declawed \u0026lt;chr\u0026gt; \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;Fron‚Ä¶ ## $ Distinguishing.Markings \u0026lt;chr\u0026gt; \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;‚Ä¶ ## $ Purebred \u0026lt;int\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶ ## $ BodyWeight \u0026lt;dbl\u0026gt; 0.00, 0.00, 2.00, 0.00, 0.00, 0.00, 0.00, 12.‚Ä¶ ## $ BodyWeightUnit \u0026lt;chr\u0026gt; NA, NA, \u0026quot;pound\u0026quot;, NA, NA, NA, NA, \u0026quot;pound\u0026quot;, NA,‚Ä¶ ## $ PrimaryColor \u0026lt;chr\u0026gt; \u0026quot;Black\u0026quot;, \u0026quot;Grey\u0026quot;, \u0026quot;Black\u0026quot;, \u0026quot;Orange\u0026quot;, \u0026quot;Black\u0026quot;, ‚Ä¶ ## $ SecondaryColor \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, NA, NA, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Brown\u0026quot;, N‚Ä¶ ## $ ColorPattern \u0026lt;chr\u0026gt; NA, \u0026quot;Tiger\u0026quot;, NA, NA, NA, \u0026quot;Tiger\u0026quot;, \u0026quot;Tortoisesh‚Ä¶ ## $ Intake.Date \u0026lt;date\u0026gt; 2000-03-18, 2000-04-06, 2000-05-02, 2000-05-‚Ä¶ ## $ Intake.Type \u0026lt;chr\u0026gt; \u0026quot;Owner/Guardian Surrender\u0026quot;, \u0026quot;Stray\u0026quot;, \u0026quot;Owner/G‚Ä¶ ## $ Intake.Subtype \u0026lt;chr\u0026gt; \u0026quot;Schedule\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, ‚Ä¶ ## $ Reason \u0026lt;chr\u0026gt; \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Too Many Pets\u0026quot;, \u0026quot;Too Many Pets\u0026quot;, \u0026quot;\u0026quot;,‚Ä¶ ## $ Reason.Category \u0026lt;chr\u0026gt; NA, NA, \u0026quot;Owner problem\u0026quot;, \u0026quot;Owner problem\u0026quot;, NA,‚Ä¶  How old are the cats? # calculate age in days cat_claw$diff_in_days \u0026lt;- cat_claw$Intake.Date - cat_claw$Date.Of.Birth summary(cat_claw$diff_in_days) # summary for class type: \u0026#39;difftime\u0026#39; ## Length Class Mode ## 200 difftime numeric # summary for diff_in_days as numeric (does everything seem ok?) summary(as.numeric(cat_claw$diff_in_days)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -322 122 730 1070 1822 5114 # Identify \u0026#39;incorrect\u0026#39; observation(s) # identify negative diff_in_days; how many? ind \u0026lt;- which.min(as.numeric(cat_claw$diff_in_days)) ind ## [1] 30 # remove observations with intake date before date of bearth # save it as a new data set cat \u0026lt;- cat_claw[-ind,] # replace empty spaces with NA cat$Animal.Name[cat$Animal.Name == \u0026quot;\u0026quot;] \u0026lt;- NA cat$Distinguishing.Markings[cat$Distinguishing.Markings == \u0026quot;\u0026quot;] \u0026lt;- NA cat$Reason[cat$Reason == \u0026quot;\u0026quot;] \u0026lt;- NA # Check the data glimpse(cat) ## Rows: 199 ## Columns: 21 ## $ Animal.ID \u0026lt;int\u0026gt; 1032415, 1032962, 1033799, 1033965, 1038328, ‚Ä¶ ## $ Animal.Name \u0026lt;chr\u0026gt; \u0026quot;HARLEY\u0026quot;, \u0026quot;TRUCKER\u0026quot;, NA, NA, NA, \u0026quot;PUDDY TAT\u0026quot;,‚Ä¶ ## $ Species \u0026lt;chr\u0026gt; \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Cat\u0026quot;, \u0026quot;Ca‚Ä¶ ## $ Gender \u0026lt;chr\u0026gt; \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, ‚Ä¶ ## $ Date.Of.Birth \u0026lt;date\u0026gt; 1999-09-18, 1998-04-10, 2000-02-02, 2000-03-‚Ä¶ ## $ Primary.Breed \u0026lt;chr\u0026gt; \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;Domestic Shorthair\u0026quot;, \u0026quot;‚Ä¶ ## $ Secondary.Breed \u0026lt;chr\u0026gt; \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mix\u0026quot;, \u0026quot;Mi‚Ä¶ ## $ Declawed \u0026lt;chr\u0026gt; \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;None\u0026quot;, \u0026quot;Fron‚Ä¶ ## $ Distinguishing.Markings \u0026lt;chr\u0026gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶ ## $ Purebred \u0026lt;int\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶ ## $ BodyWeight \u0026lt;dbl\u0026gt; 0.00, 0.00, 2.00, 0.00, 0.00, 0.00, 0.00, 12.‚Ä¶ ## $ BodyWeightUnit \u0026lt;chr\u0026gt; NA, NA, \u0026quot;pound\u0026quot;, NA, NA, NA, NA, \u0026quot;pound\u0026quot;, NA,‚Ä¶ ## $ PrimaryColor \u0026lt;chr\u0026gt; \u0026quot;Black\u0026quot;, \u0026quot;Grey\u0026quot;, \u0026quot;Black\u0026quot;, \u0026quot;Orange\u0026quot;, \u0026quot;Black\u0026quot;, ‚Ä¶ ## $ SecondaryColor \u0026lt;chr\u0026gt; \u0026quot;White\u0026quot;, NA, NA, \u0026quot;White\u0026quot;, \u0026quot;White\u0026quot;, \u0026quot;Brown\u0026quot;, N‚Ä¶ ## $ ColorPattern \u0026lt;chr\u0026gt; NA, \u0026quot;Tiger\u0026quot;, NA, NA, NA, \u0026quot;Tiger\u0026quot;, \u0026quot;Tortoisesh‚Ä¶ ## $ Intake.Date \u0026lt;date\u0026gt; 2000-03-18, 2000-04-06, 2000-05-02, 2000-05-‚Ä¶ ## $ Intake.Type \u0026lt;chr\u0026gt; \u0026quot;Owner/Guardian Surrender\u0026quot;, \u0026quot;Stray\u0026quot;, \u0026quot;Owner/G‚Ä¶ ## $ Intake.Subtype \u0026lt;chr\u0026gt; \u0026quot;Schedule\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, \u0026quot;Walk In\u0026quot;, ‚Ä¶ ## $ Reason \u0026lt;chr\u0026gt; NA, NA, \u0026quot;Too Many Pets\u0026quot;, \u0026quot;Too Many Pets\u0026quot;, NA,‚Ä¶ ## $ Reason.Category \u0026lt;chr\u0026gt; NA, NA, \u0026quot;Owner problem\u0026quot;, \u0026quot;Owner problem\u0026quot;, NA,‚Ä¶ ## $ diff_in_days \u0026lt;drtn\u0026gt; 182 days, 727 days, 90 days, 61 days, 3 days‚Ä¶  What to plot? Plot Age vs Declawed using Boxplot\nboxplot(as.numeric(diff_in_days) ~ Declawed, data = cat, horizontal = TRUE) Can we make it more attractive looking?\n Create graph using ggplot #The image_graph() function opens a new graphics device similar to e.g. png() or x11(). # It returns an image objec to which the plot(s) will be written fig \u0026lt;- image_graph(width = 600, height = 600, res = 96) # plots Age (in years) vs Declawed and saves it as an image ggplot(cat, aes(Declawed, round(as.numeric(diff_in_days)/365), 2)) + geom_boxplot(outlier.size = 0) + geom_jitter(position=position_jitter(width=0.30), shape = 20, size = 3, aes(colour=Declawed), alpha=0.75) + stat_summary(fun.y=mean, shape=23, size = 3, fill = \u0026quot;orange\u0026quot;, col= \u0026quot;black\u0026quot;, geom=\u0026#39;point\u0026#39;) + labs (title= \u0026quot;Cats: Age vs Declawed \u0026quot;, x = \u0026quot; Declawed\u0026quot;, y = \u0026quot; Age\u0026quot;) + theme(panel.border = element_rect(fill = NA, colour = \u0026quot;black\u0026quot;, size = 2)) + theme(plot.title = element_text(size = 20, vjust = 2)) + ggsave(\u0026#39;~/Documents/my_R/RLadiesMNE/ggplot_image.png\u0026#39;)  ## Warning: `fun.y` is deprecated. Use `fun` instead. ## Saving 6.25 x 6.25 in image  Adding an animation to a graph: Read gif and background files\n# read cat gif file cat_gif \u0026lt;- image_read(\u0026quot;http://media.giphy.com/media/q0ujUmppx3Fu0/giphy.gif\u0026quot;) # # Background image graph_bg \u0026lt;- image_read(\u0026quot;~/Documents/my_R/RLadiesMNE/ggplot_image.png\u0026quot;) background \u0026lt;- image_background(image_scale(graph_bg, \u0026quot;650\u0026quot;), \u0026quot;white\u0026quot;, flatten = TRUE) # Combine and flatten frames frames \u0026lt;- image_apply(cat_gif, function(frame) { image_composite(background, frame, offset = \u0026quot;+410+10\u0026quot;) }) # Turn frames into animation animation \u0026lt;- image_animate(frames, fps = 10) print(animation)   Happy Plotting!  ","date":1503792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503792000,"objectID":"79e77de9a5dd850b0f62028b0b949952","permalink":"/post/why_r/","publishdate":"2017-08-27T00:00:00Z","relpermalink":"/post/why_r/","section":"post","summary":"The R language provides a rich and flexible environment for working with data, especially data to be used for statistical modelling or graphics.\n R is a comprehensive public domain language for data analysis, with no licensing costs associated with it.","tags":null,"title":"Why R? An illustration through the use of ggplot and magick","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Tatjana Kecojevic","Alan Derbyshire"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1404777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404777600,"objectID":"2e830a9564f9136d0e04855ec2f1a7b2","permalink":"/publication/vei/","publishdate":"2014-07-08T00:00:00Z","relpermalink":"/publication/vei/","section":"publication","summary":"This study focuses on the development of the Boka Kotorska region of Montenegro. As such it attempts to analyse the viability of sustainable development in the region and considers the role of vernacular architecture and ecology as contributory factors.","tags":null,"title":"The Boka Kotorska$\\colon$ Vernacular Response to Sustainable Urban Environments.","type":"publication"},{"authors":null,"categories":null,"content":"   Click on the PDF button above to view the slides.   ","date":1340841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1340841600,"objectID":"dd07e9966e72d392b581c0de2814585c","permalink":"/talk/user2016/","publishdate":"2016-06-30T00:00:00Z","relpermalink":"/talk/user2016/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":["quantile regression","bootstrapping","kernel smoothing","general linear model","rstats"],"title":"Data Landscapes$\\colon$ a pragmatic and philosophical visualisation of the sustainable urban landscape","type":"talk"},{"authors":null,"categories":null,"content":"   Click on the PDF button above to view the slides.   ","date":1339459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1339459200,"objectID":"f5c60dce51564a33294c3a5c09044c30","permalink":"/talk/user2012/","publishdate":"2012-06-15T00:00:00Z","relpermalink":"/talk/user2012/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":["quantile regression","bootstrapping","kernel smoothing","general linear model","rstats"],"title":"Smooth Bootstrap Inference for Parametric Quantile Regression","type":"talk"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1272672000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1272672000,"objectID":"9781849fd556eedb105ef80aa2a3d4eb","permalink":"/publication/regional_disparity/","publishdate":"2010-05-01T00:00:00Z","relpermalink":"/publication/regional_disparity/","section":"publication","summary":"Data for this study were collected over 2 years (2004 and 2005). A cross-sectional representative sample of the Saudi population of healthy children below 5 years of age was used to calculate the prevalence of malnutrition. The study was carried out in the College of Medicine, King Saud University, Riyadh, Kingdom of Saudi Arabia. Body measurements of the weight, length, and height were performed according to standard recommendations. Standard deviation scores were determined using the Lambda, Mu, and Sigma (LMS) statistical methodology. The 1978 NCHS/WHO growth reference was used for the calculation of prevalence of underweight, wasting, and stunting defined as the proportion of children whose weight for age, weight for height, and height for age was below minus standard deviation (-2 SD) for Northern, Southwestern, and Central regions of the Kingdom of Saudi Arabia. Chi-square test was used to assess the difference in prevalence between regions, and a p","tags":null,"title":"Regional disparity in prevalence of malnutrition in Saudi children","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1264982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1264982400,"objectID":"98c1e21799f87fd494d534a6b956b63d","permalink":"/publication/pattern_sex_differences/","publishdate":"2010-02-01T00:00:00Z","relpermalink":"/publication/pattern_sex_differences/","section":"publication","summary":"The data set was based on a cross-sectional representative sample of the Saudi population of healthy children and adolescents from birth to 19 years of age. Body measurements (length, height, weight, and head circumference) were performed according to standard recommendations; body mass index was also determined for each subject. The difference in growth between boys and girls was assessed based on z scores and percentiles (5th, 50th, and 95th) of growth parameters using 2 age groups (0‚Äì3 years and 2‚Äì19 years). The significance of the difference between boys and girls for any growth parameter was tested by ANCOVA.","tags":null,"title":"Pattern of sex differences in growth of Saudi children and adolescents","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1264982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1264982400,"objectID":"9d43579046d0e3dd48cc44ee62eb49f9","permalink":"/publication/prevalence/","publishdate":"2010-02-01T00:00:00Z","relpermalink":"/publication/prevalence/","section":"publication","summary":"The data set of the 2005 Saudi reference was used to calculate the BMI for age in children below 60 months of age. The prevalence of overweight was calculated based on the two references using the WHO cutoffs (weight for height or BMI for age above +2 standard deviation score). A lower cutoff for excess weight, BMI for age  + 1 SDS (equivalent CDC cut off for overweight) was also used. All calculations were performed using the WHO and CDC software as appropriate. Chisquare test was used to compare proportions and a p-value ","tags":null,"title":"Prevalence of overweight in preschool children using the new WHO growth standards","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1260835200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1260835200,"objectID":"912855cacdf750483fbd66f850ac3062","permalink":"/publication/reference-growth-charts/","publishdate":"2009-12-15T00:00:00Z","relpermalink":"/publication/reference-growth-charts/","section":"publication","summary":"The purpose of this study is to provide Saudi Arabian population reference growth standards for height, weight, body mass index (BMI), head circumference and weight for length/stature. The estimated distribution centiles are obtained by splitting the population into two separate age groups$\\colon$ infants, birth to 36 months and children and adolescents, age 2 to 19 years. The reference values were derived from cross-sectional data applying the LMS method of Cole and Green (Stat. in Medicine 1992; 11:1305-1319) using the lmsqreg package in R (public domain language for data analysis, 2009). The report provides an overview of how the method has been applied, more specifcally how the relevant issues concerning the construction of the growth charts have been addressed and is illustrated by just using the girls weight data (birth to three years old). These issues include identifying the outliers, diagnosing the appropriate amounts of smoothing and averaging the reference standards for the overlapping 2 to 3 year age range. The use of ANCOVA has been introduced and illustrated as a tool for making growth standard comparisons between different geographical regions and between genders.","tags":null,"title":"Reference growth charts for Saudi Arabian children and adolescents","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.    Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.     Click the Slides button above to demo Academic‚Äôs Markdown slides feature.   ","date":1254355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1254355200,"objectID":"cced6d6894551f53086d48b9731fbfaa","permalink":"/publication/regional_variations/","publishdate":"2009-10-01T00:00:00Z","relpermalink":"/publication/regional_variations/","section":"publication","summary":"The 2005 Saudi reference was based on a cross-sectional representative sample of the Saudi population of healthy children and adolescents from birth to 18 years of age. Body measurements of the length, stature, weight, head circumference and calculation of the BMI were performed according to stan- dard recommendations. Percentile construction and smoothing were performed using the LMS (lambda, mu and sigma) methodology, followed by transformation of all individual measurements into standard deviation scores. Factors such as weight for age, height for age, weight for height, and head circumference for children from birth to 3 years, stature for age, head circumference and body mass index for children between 2-18 years of age were assessed. Subsequently, variations in growth between the three main regions in the north, southwest, and center of Saudi Arabia were calculated, with the Bonferoni$\\colon$  method used to assess the significance of differences between regions.","tags":null,"title":"Regional variations in the growth of Saudi children and adolescents","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1251763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1251763200,"objectID":"98afe4a7a8b9bbdc9a5ed7b26aa0e712","permalink":"/publication/bmi/","publishdate":"2009-09-01T00:00:00Z","relpermalink":"/publication/bmi/","section":"publication","summary":"Data from a stratified multistage probability sample were collected from the 13 health regions in Saudi Arabia, as part of a nationwide health profile survey of Saudi Arabian children and adolescents conducted to establish normal physical growth references. Selected households were visited by a trained team. Weight and length/height were measured and recorded following the WHO recommended procedures using the same equipment, which were subjected to both calibration and intra/interobserver variations.","tags":null,"title":"Body mass index in Saudi Arabian children and adolescents$\\colon$ a national reference and comparison with international standards","type":"publication"},{"authors":null,"categories":null,"content":"   Click on the PDF button above to view the slides.   ","date":1245283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1245283200,"objectID":"dd282a7024ca2048cb35bc1226aecd44","permalink":"/talk/fordham/","publishdate":"2009-06-18T00:00:00Z","relpermalink":"/talk/fordham/","section":"talk","summary":"The purpose of this study is to provide Saudi Arabian population reference growth standards for height, weight, body mass index (BMI), head circumference and weight for length/stature. The estimated distribution centiles are obtained by splitting the population into two separate age groups$\\colon$ infants, birth to 36 months and children and adolescents, age 2 to 19 years. The reference values were derived from cross-sectional data applying the LMS method of Cole and Green (Stat. in Medicine 1992; 11:1305-1319) using the lmsqreg package in R (public domain language for data analysis, 2009). The report provides an overview of how the method has been applied, more specifcally how the relevant issues concerning the construction of the growth charts have been addressed and is illustrated by just using the girls weight data (birth to three years old). These issues include identifying the outliers, diagnosing the appropriate amounts of smoothing and averaging the reference standards for the overlapping 2 to 3 year age range. The use of ANCOVA has been introduced and illustrated as a tool for making growth standard comparisons between different geographical regions and between genders.","tags":["rstats","quantile regression"],"title":"Construction of the Reference Growth Charts for Saudi Arabian Children and Adolescents","type":"talk"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1238544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1238544000,"objectID":"359a7002a2083b8f84600a95cb894600","permalink":"/publication/implications_who/","publishdate":"2009-04-01T00:00:00Z","relpermalink":"/publication/implications_who/","section":"publication","summary":"The World Health Organization (WHO) has recently released a new child growth standard that it recommends for international use. The objective of this study was to demonstrate the differences and the implications of using the WHO child growth standards on Saudi children. The Saudi reference was based on a cross-sectional sample of the population of healthy children and adolescents from birth to 19 years of age. The WHO sample was selected from privileged households in some countries. Percentile construction and smoothing were performed using the lambda, mu, sigma (LMS) methodology in both studies. The data from the WHO study including the 3rd, 5th, 50th, 95th, and 97th percentiles were plotted on the Saudi charts for weight for age, height for age, and weight for height. There are major differences between the 2 studies. Compared with the Saudi charts, the WHO lower percentiles (third and fifth) are shifted upward, whereas the upper percentiles are shifted downward. The use of the WHO standards in Saudi Arabia and possibly in other countries of similar socioeconomic status increases the prevalence of undernutrition, stunting, and wasting, potentially leading to unnecessary referrals, investigations, and parental anxiety. Clear guidelines should be developed by WHO experts to guide clinicians in developing countries in the proper use of the standards not only to determine prevalence but also in the daily clinical assessment of the growth of children.","tags":null,"title":"The Implications of Using the World Health Organization Child Growth Standards in Saudi Arabia","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1228089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1228089600,"objectID":"e1c793b0b2b96afce1f15b6763451ec1","permalink":"/publication/comparison_cdc/","publishdate":"2008-12-01T00:00:00Z","relpermalink":"/publication/comparison_cdc/","section":"publication","summary":"The Saudi reference was based on a cross-sectional representative sample of the Saudi population of healthy children and adolescents from birth to 19 years of age. Measurements of the length/ stature, weight and head circumference were performed according to expert recommendations. The CDC charts from birth to 20 years were based on a cross-sectional representative national sample from five sources collected between 1963 and 1994. The data from the CDC study including the 3rd, 5th, 50th, 95th, and 97th percentiles were plotted against the corresponding percentiles on the Saudi charts for the weight for age, height for age, weight for height for children from 0 to 36 months and weight for age, stature for age and body mass index for children 2 to 19 years of age.","tags":null,"title":"Comparison of the 2005 growth charts for Saudi children and adolescents to the 2000 CDC growth charts","type":"publication"},{"authors":["Tatjana Kecojevic","Peter Foster"],"categories":null,"content":"   Click the Cite button above to enable to import publication metadata into your reference management software.   ","date":1157068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1157068800,"objectID":"2aebe4b1bc1f5053d664e37863955223","permalink":"/publication/adiposity/","publishdate":"2006-09-01T00:00:00Z","relpermalink":"/publication/adiposity/","section":"publication","summary":"Growth measurements of 70 male and 40 female patients with AD followed through childhood and adolescence were studied retrospectively and compared with the 1990 U.K. normal values. Height, weight and body mass index (BMI) were converted to standard deviation scores (SDS). Regression analysis examined whether the mean trend was different from zero.","tags":null,"title":"Pattern of growth and adiposity from infancy to adulthood in atopic dermatitis","type":"publication"}]